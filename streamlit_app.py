"""
Streamlit Application for Course Analytics Processing
Upload files and process course data automatically with Supabase database
"""

import streamlit as st
import pandas as pd
from supabase import create_client, Client
import os
import tempfile
import time
from io import StringIO
from datetime import datetime
from separated_db_functions import upload_students_to_supabase, upload_all_courses_to_supabase

# Page configuration
st.set_page_config(
    page_title="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∫—É—Ä—Å–æ–≤ - Supabase",
    page_icon="üìä",
    layout="wide"
)

def authenticate_supabase():
    """–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Å Supabase –∏—Å–ø–æ–ª—å–∑—É—è Streamlit secrets"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–µ–∫—Ä–µ—Ç–æ–≤ Supabase
        if not hasattr(st, 'secrets') or "supabase" not in st.secrets:
            st.error("‚ùå –°–µ–∫—Ä–µ—Ç—ã Supabase –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Streamlit")
            st.error("üí° –î–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ —Å–µ–∫—Ä–µ—Ç—ã SUPABASE_URL –∏ SUPABASE_KEY")
            return None
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∏–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤
        supabase_url = st.secrets["supabase"]["url"]
        supabase_key = st.secrets["supabase"]["key"]
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞ Supabase
        supabase: Client = create_client(supabase_url, supabase_key)
        
        st.success("‚úÖ –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è Supabase —É—Å–ø–µ—à–Ω–∞")
        return supabase
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ Supabase: {str(e)}")
        return None

def check_supabase_connection(supabase):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase"""
    try:
        if supabase is None:
            st.error("‚ùå –ö–ª–∏–µ–Ω—Ç Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return False
        
        st.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ course_analytics
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å —Å—Ö–µ–º—É —Ç–∞–±–ª–∏—Ü—ã
            result = supabase.table('course_analytics').select('*').limit(1).execute()
            st.success("‚úÖ –¢–∞–±–ª–∏—Ü–∞ 'course_analytics' –¥–æ—Å—Ç—É–ø–Ω–∞")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–æ–ª–æ–Ω–∫–∞ "–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã"
            if result.data:
                # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                sample_record = result.data[0]
                if '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã' not in sample_record:
                    st.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –î–æ–±–∞–≤–ª—è–µ–º...")
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â—É—é –∫–æ–ª–æ–Ω–∫—É
                    alter_sql = """
                    ALTER TABLE course_analytics 
                    ADD COLUMN IF NOT EXISTS –≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã TEXT;
                    """
                    try:
                        alter_result = supabase.rpc('exec_sql', {'sql': alter_sql}).execute()
                        st.success("‚úÖ –ö–æ–ª–æ–Ω–∫–∞ '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã' –¥–æ–±–∞–≤–ª–µ–Ω–∞")
                    except Exception as alter_error:
                        st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É: {str(alter_error)}")
                        st.info("üí° –í—ã–ø–æ–ª–Ω–∏—Ç–µ –≤ Supabase SQL Editor:")
                        st.code(alter_sql, language='sql')
                else:
                    st.success("‚úÖ –ö–æ–ª–æ–Ω–∫–∞ '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã' –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –Ω–∞ –∑–∞–ø–∏—Å—å (—Ç–µ—Å—Ç–æ–≤–∞—è –∑–∞–ø–∏—Å—å)
            test_record = {
                '—Ñ–∏–æ': f'–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è {datetime.now().strftime("%H:%M:%S")}',
                '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞': 'test@connection.check',
                '—Ñ–∏–ª–∏–∞–ª_–∫–∞–º–ø—É—Å': '–¢–µ—Å—Ç',
                '—Ñ–∞–∫—É–ª—å—Ç–µ—Ç': '–¢–µ—Å—Ç',
                '–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_–ø—Ä–æ–≥—Ä–∞–º–º–∞': '–¢–µ—Å—Ç',
                '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã': '–¢–µ—Å—Ç',
                '–≥—Ä—É–ø–ø–∞': '–¢–µ—Å—Ç',
                '–∫—É—Ä—Å': '–¢–µ—Å—Ç',
                '–ø—Ä–æ—Ü–µ–Ω—Ç_—Ü–≥': 0.0,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_–ø–∏—Ç–æ–Ω': 0.0,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_–∞–Ω–¥–∞–Ω': 0.0,
                'created_at': datetime.now().isoformat()
            }
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∑–∞–ø–∏—Å—å
            insert_result = supabase.table('course_analytics').insert(test_record).execute()
            
            if insert_result.data:
                test_id = insert_result.data[0]['id']
                st.success("‚úÖ –ü—Ä–∞–≤–∞ –Ω–∞ –∑–∞–ø–∏—Å—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã")
                
                # –£–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∑–∞–ø–∏—Å—å
                supabase.table('course_analytics').delete().eq('id', test_id).execute()
                st.success("‚úÖ –ü—Ä–∞–≤–∞ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã")
            else:
                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")
                return False
                
        except Exception as e:
            if "relation \"course_analytics\" does not exist" in str(e).lower():
                st.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ 'course_analytics' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                if not create_course_analytics_table(supabase):
                    return False
            elif "row-level security policy" in str(e).lower() or "42501" in str(e):
                st.error("‚ùå –û—à–∏–±–∫–∞ Row Level Security (RLS): –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –ø–æ–ª–∏—Ç–∏–∫–∞–º–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
                st.error("üí° –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å RLS –ø–æ–ª–∏—Ç–∏–∫–∏ –≤ Supabase Dashboard:")
                st.code("""
-- –í Supabase SQL Editor –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:

-- 1. –û—Ç–∫–ª—é—á–∏—Ç—å RLS –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π)
ALTER TABLE course_analytics DISABLE ROW LEVEL SECURITY;

-- –ò–õ–ò

-- 2. –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–∏—Ç–∏–∫—É –¥–ª—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π (–±–æ–ª–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
CREATE POLICY "Enable all operations for service role" ON course_analytics
FOR ALL USING (true) WITH CHECK (true);

-- 3. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ: –ø–æ–ª–∏—Ç–∏–∫–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è authenticated –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
CREATE POLICY "Enable operations for authenticated users" ON course_analytics
FOR ALL USING (auth.role() = 'authenticated') WITH CHECK (auth.role() = 'authenticated');
                """, language='sql')
                return False
            else:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ç–∞–±–ª–∏—Ü–µ: {str(e)}")
                return False
        
        st.success("üéâ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ!")
        return True
        
    except Exception as e:
        st.error(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {str(e)}")
        return False

def create_course_analytics_table(supabase):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã course_analytics –≤ Supabase"""
    try:
        st.info("üîß –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã course_analytics...")
        
        # SQL –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
        create_table_sql = """
        CREATE TABLE IF NOT EXISTS course_analytics (
            id SERIAL PRIMARY KEY,
            —Ñ–∏–æ TEXT NOT NULL,
            –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞ TEXT UNIQUE NOT NULL,
            —Ñ–∏–ª–∏–∞–ª_–∫–∞–º–ø—É—Å TEXT,
            —Ñ–∞–∫—É–ª—å—Ç–µ—Ç TEXT,
            –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_–ø—Ä–æ–≥—Ä–∞–º–º–∞ TEXT,
            –≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã TEXT,
            –≥—Ä—É–ø–ø–∞ TEXT,
            –∫—É—Ä—Å TEXT,
            –ø—Ä–æ—Ü–µ–Ω—Ç_—Ü–≥ REAL DEFAULT 0.0,
            –ø—Ä–æ—Ü–µ–Ω—Ç_–ø–∏—Ç–æ–Ω REAL DEFAULT 0.0,
            –ø—Ä–æ—Ü–µ–Ω—Ç_–∞–Ω–¥–∞–Ω REAL DEFAULT 0.0,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
            updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
        );
        
        -- –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –Ω–∞ email –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        CREATE INDEX IF NOT EXISTS idx_course_analytics_email 
        ON course_analytics(–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞);
        
        -- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è updated_at
        CREATE OR REPLACE FUNCTION update_updated_at_column()
        RETURNS TRIGGER AS $$
        BEGIN
            NEW.updated_at = NOW();
            RETURN NEW;
        END;
        $$ language 'plpgsql';
        
        -- –¢—Ä–∏–≥–≥–µ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è updated_at
        DROP TRIGGER IF EXISTS update_course_analytics_updated_at ON course_analytics;
        CREATE TRIGGER update_course_analytics_updated_at
            BEFORE UPDATE ON course_analytics
            FOR EACH ROW
            EXECUTE FUNCTION update_updated_at_column();
        """
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º SQL —á–µ—Ä–µ–∑ RPC (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è) –∏–ª–∏ —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å
        try:
            result = supabase.rpc('exec_sql', {'sql': create_table_sql}).execute()
            st.success("‚úÖ –¢–∞–±–ª–∏—Ü–∞ course_analytics —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return True
        except Exception as rpc_error:
            st.warning(f"‚ö†Ô∏è RPC –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {str(rpc_error)}")
            st.info("üí° –°–æ–∑–¥–∞–π—Ç–µ —Ç–∞–±–ª–∏—Ü—É course_analytics –≤—Ä—É—á–Ω—É—é –≤ Supabase Dashboard")
            st.code(create_table_sql, language='sql')
            return False
            
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã: {str(e)}")
        return False

def load_student_list(uploaded_file):
    """Load student list from uploaded Excel or CSV file"""
    try:
        # Determine file type and load accordingly
        file_name = uploaded_file.name.lower()
        if file_name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        elif file_name.endswith('.csv'):
            # Check encoding and try different options
            content = uploaded_file.getvalue()
            try:
                # Try UTF-16 with tab delimiter first (based on project memory)
                df = pd.read_csv(StringIO(content.decode('utf-16')), sep='\t')
            except (UnicodeDecodeError, pd.errors.ParserError):
                try:
                    # Try UTF-8 with comma delimiter
                    df = pd.read_csv(StringIO(content.decode('utf-8')))
                except UnicodeDecodeError:
                    # Try cp1251 encoding (common for Russian files)
                    df = pd.read_csv(StringIO(content.decode('cp1251')))
        else:
            st.error("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Excel (.xlsx, .xls) –∏–ª–∏ CSV (.csv)")
            return None
        
        # Map columns to required format
        required_columns = {
            '–§–ò–û': ['—Ñ–∏–æ', '—Ñio', '–∏–º—è', 'name'],
            '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞': ['–∞–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', 'email', '–ø–æ—á—Ç–∞', 'e-mail'],
            '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)': ['—Ñ–∏–ª–∏–∞–ª', '–∫–∞–º–ø—É—Å', 'campus'],
            '–§–∞–∫—É–ª—å—Ç–µ—Ç': ['—Ñ–∞–∫—É–ª—å—Ç–µ—Ç', 'faculty'],
            '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞': ['–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ø—Ä–æ–≥—Ä–∞–º–º–∞', 'educational program'],
            '–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã': ['–≤–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '–≤–µ—Ä—Å–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã', 'program version', 'version'],
            '–ì—Ä—É–ø–ø–∞': ['–≥—Ä—É–ø–ø–∞', 'group'],
            '–ö—É—Ä—Å': ['–∫—É—Ä—Å', 'course']
        }
        
        # Find matching columns in the file
        found_columns = {}
        df_columns_lower = [str(col).lower().strip() for col in df.columns]
        
        for target_col, possible_names in required_columns.items():
            for col_idx, col_name in enumerate(df_columns_lower):
                if any(possible_name in col_name for possible_name in possible_names):
                    found_columns[target_col] = df.columns[col_idx]
                    break
        
        # Create new DataFrame with required columns
        result_df = pd.DataFrame()
        for target_col, source_col in found_columns.items():
            if source_col in df.columns:
                result_df[target_col] = df[source_col]
        
        # Check for '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ' column and parse it according to specification
        if '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ' in df.columns:
            user_data = df['–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ'].astype(str)
            parsed_data = user_data.str.split(';', expand=True)
            if len(parsed_data.columns) >= 4:
                result_df['–§–∞–∫—É–ª—å—Ç–µ—Ç'] = parsed_data[0]
                result_df['–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞'] = parsed_data[1] 
                result_df['–ö—É—Ä—Å'] = parsed_data[2]
                result_df['–ì—Ä—É–ø–ø–∞'] = parsed_data[3]
        
        # Add missing columns with empty values
        for required_col in required_columns.keys():
            if required_col not in result_df.columns:
                result_df[required_col] = ''
        
        # Filter only students with edu.hse.ru email
        if '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞' in result_df.columns:
            result_df = result_df[result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'].astype(str).str.contains('@edu.hse.ru', na=False)]
            result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'] = pd.Series(result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞']).astype(str).str.lower().str.strip()
        
        return result_df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {str(e)}")
        return None

def extract_course_data(uploaded_file, course_name):
    """Extract email and completion percentage from uploaded course file (CSV or Excel)"""
    try:
        # Determine file type and load accordingly
        file_name = uploaded_file.name.lower()
        if file_name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        elif file_name.endswith('.csv'):
            # Read the uploaded file with different encoding options
            content = uploaded_file.getvalue()
            try:
                # Try UTF-16 with tab delimiter first (based on project memory)
                df = pd.read_csv(StringIO(content.decode('utf-16')), sep='\t')
            except (UnicodeDecodeError, pd.errors.ParserError):
                try:
                    # Try UTF-8 with comma delimiter
                    df = pd.read_csv(StringIO(content.decode('utf-8')))
                except UnicodeDecodeError:
                    # Try cp1251 encoding (common for Russian files)
                    df = pd.read_csv(StringIO(content.decode('cp1251')))
        else:
            st.error(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Excel (.xlsx, .xls) –∏–ª–∏ CSV (.csv)")
            return None
        
        # Look for email column with different possible names
        email_column = None
        possible_email_names = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', 'Email', '–ü–æ—á—Ç–∞', 'E-mail']
        
        for col_name in possible_email_names:
            if col_name in df.columns:
                email_column = col_name
                break
        
        if email_column is None:
            st.error(f"–°—Ç–æ–ª–±–µ—Ü —Å email –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ {course_name}. –û–∂–∏–¥–∞—é—Ç—Å—è —Å—Ç–æ–ª–±—Ü—ã: {', '.join(possible_email_names)}")
            return None
        
        # Look for completion percentage column
        completion_column = None
        possible_completion_names = ['–ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è', 'Completion', 'Progress', '–ü—Ä–æ–≥—Ä–µ—Å—Å', '–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ']
        
        # Also check if we need to calculate completion from multiple columns
        # Look for columns that might contain completion data
        completed_columns = []
        timestamp_columns = []
        
        # –ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –∫—É—Ä—Å–∞ –¶–ì (–Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤)
        # –í–ê–ñ–ù–û: –ò—Å–∫–ª—é—á–∞–µ–º —Å–ø—Ä–∞–≤–æ—á–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã, —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏, –ø—Ä–æ–º–æ-–∫–æ–Ω—Ç–µ–Ω—Ç –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É—á–µ–±–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è
        cg_excluded_keywords = [
            # –°–ø—Ä–∞–≤–æ—á–Ω—ã–µ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã
            'take away', '—à–ø–∞—Ä–≥–∞–ª–∫–∞', '–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è', '–æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è', '–ø—Ä–æ–º–æ-—Ä–æ–ª–∏–∫',
            '–ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤', '–ø–æ—è—Å–Ω–µ–Ω–∏–µ', '—Å–ª—É—á–∞–π–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ —Å –æ–≤–∑',
            '–º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø–æ –º–æ–¥—É–ª—é', '–∫–æ–ø–∏—è',
            
            # –≠–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏  
            '–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç', '—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è', '–¥–µ–º–æ-–≤–µ—Ä—Å–∏—è',
            '–ø—Ä–∞–≤–∏–ª–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–≥–æ —ç–∫–∑–∞–º–µ–Ω–∞', '–ø–æ—Ä—è–¥–æ–∫ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö —ç–∫–∑–∞–º–µ–Ω–æ–≤',
            '–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–∞–∂–µ—Ä –ø—Ä–∞–≤–∏–ª –Ω—ç', '–ø–µ—Ä–µ—Å–¥–∞—á–∏ –≤ —Å–µ–Ω—Ç—è–±—Ä–µ', '–Ω–µ–∑—Ä—è—á–∏—Ö –∏ —Å–ª–∞–±–æ–≤–∏–¥—è—â–∏—Ö',
            
            # –ü—Ä–æ–µ–∫—Ç–Ω—ã–µ —Ä–∞–±–æ—Ç—ã (–Ω–µ –≤—Ö–æ–¥—è—Ç –≤ –æ—Å–Ω–æ–≤–Ω—É—é –ø—Ä–æ–≥—Ä–∞–º–º—É)
            '–ø—Ä–æ–µ–∫—Ç—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ tei',
            
            # –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∏ –æ–±—É—á–∞—é—â–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã (–Ω–µ –æ—Ü–µ–Ω–∏–≤–∞–µ–º—ã–µ)
            '—Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π —Ç–µ—Å—Ç', '–∫–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã tei', '–±–∞–∑–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ tie',
            '—Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏ tei', '–±—É–¥—É—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–º–∏',
            
            # –û–ø—Ä–æ—Å—ã –∏ –∞–Ω–∫–µ—Ç—ã (–Ω–µ –æ—Ü–µ–Ω–∏–≤–∞–µ–º—ã–µ)
            '–æ–ø—Ä–æ—Å', '—Ç–µ—Å—Ç –ø–æ –º–æ–¥—É–ª—é', '–∞–Ω–∫–µ—Ç–∞',
            
            # –°–∏—Å—Ç–µ–º–Ω—ã–µ –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            'user information', '—Å—Ç—Ä–∞–Ω–∞', 'user_id', '–¥–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ'
        ]
        
        # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ –¶–ì
        excluded_count = 0
        included_count = 0
        
        for col in df.columns:
            if col not in ['Unnamed: 0', email_column, '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ', 'User information', '–°—Ç—Ä–∞–Ω–∞']:
                # –î–ª—è –∫—É—Ä—Å–∞ –¶–ì –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–∏—Å–æ–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
                if course_name == '–¶–ì':
                    should_exclude = False
                    col_str = str(col).strip().lower()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
                    for excluded_keyword in cg_excluded_keywords:
                        if excluded_keyword.lower() in col_str:
                            should_exclude = True
                            excluded_count += 1
                            # –ù–µ –≤—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–∂–¥–æ–π –∏—Å–∫–ª—é—á–µ–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–µ
                            break
                    
                    if should_exclude:
                        continue
                    # –ù–µ –≤—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–∂–¥–æ–π –≤–∫–ª—é—á–µ–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–µ
                    included_count += 1
                
                # Check if this column contains completion data
                if not col.startswith('Unnamed:') and len(str(col).strip()) > 0:
                    # Sample some values to see if they contain "–í—ã–ø–æ–ª–Ω–µ–Ω–æ" –∏–ª–∏ "–ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ"
                    sample_values = df[col].dropna().astype(str).head(100)
                    if any('–í—ã–ø–æ–ª–Ω–µ–Ω–æ' in str(val) or '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ' in str(val).lower() for val in sample_values):
                        # Skip informational columns (based on experience memory)
                        if not all(str(val) == '–ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ' for val in sample_values if pd.notna(val)):
                            completed_columns.append(col)
                elif col.startswith('Unnamed:') and col != 'Unnamed: 0':
                    # Check if this unnamed column contains timestamps (completion indicators)
                    sample_values = df[col].dropna().astype(str).head(20)
                    for val in sample_values:
                        val_str = str(val).strip()
                        # Check if it looks like a timestamp
                        if any(pattern in val_str for pattern in ['2020', '2021', '2022', '2023', '2024']) and ':' in val_str:
                            timestamp_columns.append(col)
                            break
        
        # –°–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¶–ì
        if course_name == '–¶–ì':
            total_relevant_columns = excluded_count + included_count
            st.success(f"üìä –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¶–ì: –∏—Å–∫–ª—é—á–µ–Ω–æ {excluded_count} –∫–æ–ª–æ–Ω–æ–∫, –≤–∫–ª—é—á–µ–Ω–æ {included_count} –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ {total_relevant_columns} –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö")
        
        # If we found timestamp columns, use them for completion calculation
        if timestamp_columns:
            if course_name == '–¶–ì':
                st.success(f"‚úÖ –ö—É—Ä—Å –¶–ì: –Ω–∞–π–¥–µ–Ω–æ {len(timestamp_columns)} —Å—Ç–æ–ª–±—Ü–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ (–∏—Å–∫–ª—é—á–µ–Ω—ã —Å–ø—Ä–∞–≤–æ—á–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã)")
            else:
                st.info(f"–ù–∞–π–¥–µ–Ω–æ {len(timestamp_columns)} —Å—Ç–æ–ª–±—Ü–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            
            # Calculate completion percentage based on timestamps
            completion_data = []
            for idx, row in df.iterrows():
                email_val = row[email_column]
                if pd.isna(email_val) or '@edu.hse.ru' not in str(email_val).lower():
                    continue
                
                total_tasks = len(timestamp_columns)
                completed_tasks = 0
                
                for col in timestamp_columns:
                    cell_val = row[col]
                    val_str = str(cell_val).strip() if not pd.isna(cell_val) else ''
                    # Check if there's a valid timestamp (indicates completion)
                    if val_str and val_str != 'nan' and val_str != '':
                        # Verify it looks like a timestamp
                        if any(pattern in val_str for pattern in ['2020', '2021', '2022', '2023', '2024']) and ':' in val_str:
                            completed_tasks += 1
                
                # Calculate percentage
                percentage = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                completion_data.append({'email': str(email_val).lower().strip(), 'percentage': percentage})
            
            # Create result DataFrame
            if completion_data:
                result_df = pd.DataFrame(completion_data)
                result_df.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
                st.success(f"‚úÖ –†–∞—Å—Å—á–∏—Ç–∞–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è {len(result_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫—É—Ä—Å–∞ {course_name} –Ω–∞ –æ—Å–Ω–æ–≤–µ {len(timestamp_columns)} –∑–∞–¥–∞–Ω–∏–π")
                return result_df
            else:
                st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
                return None
        
        # If we found completion tracking columns, calculate percentage
        elif completed_columns:
            st.info(f"–ù–∞–π–¥–µ–Ω–æ {len(completed_columns)} —Å—Ç–æ–ª–±—Ü–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            
            # Calculate completion percentage
            completion_data = []
            for idx, row in df.iterrows():
                email_val = row[email_column]
                if pd.isna(email_val) or '@edu.hse.ru' not in str(email_val).lower():
                    continue
                
                total_tasks = 0
                completed_tasks = 0
                
                for col in completed_columns:
                    cell_val = row[col]
                    val = str(cell_val).strip() if not pd.isna(cell_val) else ''
                    if val and val != 'nan':
                        total_tasks += 1
                        if '–í—ã–ø–æ–ª–Ω–µ–Ω–æ' in val or '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ' in val.lower():
                            completed_tasks += 1
                
                # Calculate percentage
                percentage = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                completion_data.append({'email': str(email_val).lower().strip(), 'percentage': percentage})
            
            # Create result DataFrame
            if completion_data:
                result_df = pd.DataFrame(completion_data)
                result_df.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
                st.success(f"‚úÖ –†–∞—Å—Å—á–∏—Ç–∞–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è {len(result_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫—É—Ä—Å–∞ {course_name}")
                return result_df
            else:
                st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
                return None
        
        # Fallback: look for direct completion percentage column
        for col_name in possible_completion_names:
            if col_name in df.columns:
                completion_column = col_name
                break
        
        if completion_column is None:
            st.error(f"–°—Ç–æ–ª–±–µ—Ü —Å –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ {course_name}. –û–∂–∏–¥–∞—é—Ç—Å—è —Å—Ç–æ–ª–±—Ü—ã: {', '.join(possible_completion_names)}")
            st.info(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {', '.join([col for col in df.columns[:10]])}")
            return None
        
        # Extract the specific columns we need
        course_data = df[[email_column, completion_column]].copy()
        course_data.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
        course_data['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'] = pd.Series(course_data['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞']).astype(str).str.lower().str.strip()
        
        # Filter only edu.hse.ru emails
        email_series = pd.Series(course_data['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'])
        course_data = course_data[email_series.str.contains('@edu.hse.ru', na=False)]
        
        return course_data
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫—É—Ä—Å–∞ {course_name}: {str(e)}")
        return None

def consolidate_data(student_list, course_data_list, course_names):
    """Consolidate all course data with student list and deduplication"""
    try:
        # Start with student list
        consolidated = student_list.copy()
        
        # Merge each course data
        for course_data, course_name in zip(course_data_list, course_names):
            if course_data is not None:
                consolidated = pd.merge(consolidated, course_data, on='–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', how='left')
                # –ó–∞–ø–æ–ª–Ω—è–µ–º NULL –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–µ 0.0)
                consolidated[f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'] = consolidated[f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'].where(pd.notna(consolidated[f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']), None)
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ email
        st.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        initial_count = len(consolidated)
        email_counts = consolidated['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'].value_counts()
        duplicates = email_counts[email_counts > 1]
        
        if len(duplicates) > 0:
            st.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(duplicates)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ email:")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            duplicate_list = list(duplicates.index[:5])
            for email in duplicate_list:
                count = duplicates[email]
                st.text(f"  - {email}: {count} –∑–∞–ø–∏—Å–µ–π")
            if len(duplicates) > 5:
                st.text(f"  ... –∏ –µ—â—ë {len(duplicates) - 5} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, –æ—Å—Ç–∞–≤–ª—è—è –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
        consolidated = consolidated.drop_duplicates(subset=['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'], keep='first')
        
        final_count = len(consolidated)
        removed_count = initial_count - final_count
        
        if removed_count > 0:
            st.success(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤. –û—Å—Ç–∞–ª–æ—Å—å {final_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
        else:
            st.success(f"‚úÖ –î—É–±–ª–∏–∫–∞—Ç—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã. –í—Å–µ–≥–æ {final_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
        
        return consolidated
        
    except Exception as e:
        st.error(f"Error consolidating data: {str(e)}")
        return None

def upload_to_supabase(supabase, data_df, batch_size=200):
    """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Supabase —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        existing_result = supabase.table('course_analytics').select('*').execute()
        existing_data = {}
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ email
        if existing_result.data:
            for record in existing_result.data:
                email = record.get('–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞', '').lower().strip()
                if email:
                    existing_data[email] = record
        
        st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(existing_data)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        records_to_insert = []
        records_to_update = []
        unchanged_count = 0
        processed_emails = set()  # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ email –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        
        for _, row in data_df.iterrows():
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ email –∏–∑ –ø–∞–º—è—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞
            email = str(row.get('–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', '')).strip().lower()
            if not email:  # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                email = str(row.get('–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '')).strip().lower()
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å–∏ –±–µ–∑ email –∏–ª–∏ —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –¥–æ–º–µ–Ω–æ–º
            if not email or '@edu.hse.ru' not in email:
                continue
            
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ —Ç–µ–∫—É—â–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö
            if email in processed_emails:
                st.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç –≤ —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {email}")
                continue
            processed_emails.add(email)
            
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –≤ –±–∞–∑–µ –ø–æ –¢–û–ß–ù–û–ú–£ email
            email_exists_in_db = False
            for existing_email in existing_data.keys():
                if existing_email == email:
                    email_exists_in_db = True
                    break
            
            new_record = {
                '—Ñ–∏–æ': str(row.get('–§–ò–û', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')).strip() if pd.notna(row.get('–§–ò–û')) and str(row.get('–§–ò–û', '')).strip() else '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞': email if email else None,
                '—Ñ–∏–ª–∏–∞–ª_–∫–∞–º–ø—É—Å': str(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)', '')) if pd.notna(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)')) and str(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)', '')).strip() else None,
                '—Ñ–∞–∫—É–ª—å—Ç–µ—Ç': str(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç', '')) if pd.notna(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç')) and str(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç', '')).strip() else None,
                '–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_–ø—Ä–æ–≥—Ä–∞–º–º–∞': str(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '')) if pd.notna(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞')) and str(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '')).strip() else None,
                '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã': str(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '')) if pd.notna(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã')) and str(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '')).strip() else None,
                '–≥—Ä—É–ø–ø–∞': str(row.get('–ì—Ä—É–ø–ø–∞', '')) if pd.notna(row.get('–ì—Ä—É–ø–ø–∞')) and str(row.get('–ì—Ä—É–ø–ø–∞', '')).strip() else None,
                '–∫—É—Ä—Å': str(row.get('–ö—É—Ä—Å', '')) if pd.notna(row.get('–ö—É—Ä—Å')) and str(row.get('–ö—É—Ä—Å', '')).strip() else None,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_—Ü–≥': float(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–¶–ì', 0.0)) if pd.notna(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–¶–ì')) and row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–¶–ì') != '' else None,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_–ø–∏—Ç–æ–Ω': float(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ü–∏—Ç–æ–Ω', 0.0)) if pd.notna(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ü–∏—Ç–æ–Ω')) and row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ü–∏—Ç–æ–Ω') != '' else None,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_–∞–Ω–¥–∞–Ω': float(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ê–Ω–¥–∞–Ω', 0.0)) if pd.notna(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ê–Ω–¥–∞–Ω')) and row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ê–Ω–¥–∞–Ω') != '' else None
            }
            
            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –≤–µ—Ä—Å–∏–∏ –ø—Ä–æ–≥—Ä–∞–º–º—ã (—Ç–æ–ª—å–∫–æ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–æ–∫)
            version_value = new_record.get('–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —ç—Ç–æ—Ç email –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–∞–ø–∏—Å–∏)
            if email_exists_in_db:
                # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∑–∞–ø–∏—Å—å –≤ –±–∞–∑–µ
                existing_record = None
                for existing_email, record in existing_data.items():
                    if existing_email == email:
                        existing_record = record
                        break
                
                if existing_record is None:
                    # –ù–µ –Ω–∞—à–ª–∏ –∑–∞–ø–∏—Å—å - —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º –∫–∞–∫ –Ω–æ–≤—É—é
                    new_record['created_at'] = datetime.now().isoformat()
                    records_to_insert.append(new_record)
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –ª–∏ –¥–∞–Ω–Ω—ã–µ
                needs_update = False
                
                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è
                for key, value in new_record.items():
                    if key == '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞':
                        continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–ª—é—á–µ–≤–æ–µ –ø–æ–ª–µ
                    
                    existing_value = existing_record.get(key)
                    
                    # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø–æ–ª–µ–π —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —Ç–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—å—é
                    if key.startswith('–ø—Ä–æ—Ü–µ–Ω—Ç_'):
                        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º NULL –∑–Ω–∞—á–µ–Ω–∏—è
                        if value is None and existing_value is None:
                            continue
                        if value is None or existing_value is None:
                            needs_update = True
                            break
                        if abs(float(existing_value) - float(value)) > 0.01:  # –¢–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—å 0.01%
                            needs_update = True
                            break
                    else:
                        # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø–æ–ª–µ–π —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º NULL –∏ —Å—Ç—Ä–æ–∫–∏
                        existing_str = str(existing_value).strip() if existing_value is not None else None
                        new_str = str(value).strip() if value is not None else None
                        
                        # –û—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ –∫ –ø–æ–ª—é –≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã (–æ—Ç–ª–∞–¥–∫–∞ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö)
                        if key == '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã':
                            # –ï—Å–ª–∏ –≤ –±–∞–∑–µ NULL –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞, –∞ –≤ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –µ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ - –æ–±–Ω–æ–≤–ª—è–µ–º
                            if (existing_value is None or existing_str is None or existing_str == '') and new_str is not None and new_str != '':
                                needs_update = True
                                st.success(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ {email}: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –ø—Ä–æ–≥—Ä–∞–º–º—ã '{new_str}'")
                                break
                            # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è —Ä–∞–∑–Ω—ã–µ - –æ–±–Ω–æ–≤–ª—è–µ–º
                            elif existing_str != new_str:
                                needs_update = True
                                st.success(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ {email}: –∏–∑–º–µ–Ω–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ —Å '{existing_str}' –Ω–∞ '{new_str}'")
                                break
                        else:
                            if existing_str != new_str:
                                needs_update = True
                                break
                
                if needs_update:
                    new_record['id'] = existing_record['id']  # –î–æ–±–∞–≤–ª—è–µ–º ID –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                    records_to_update.append(new_record)
                else:
                    unchanged_count += 1
            else:
                # –ù–æ–≤–∞—è –∑–∞–ø–∏—Å—å
                new_record['created_at'] = datetime.now().isoformat()
                records_to_insert.append(new_record)
        
        st.info(f"üìã –ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {len(records_to_insert)} –Ω–æ–≤—ã—Ö, {len(records_to_update)} –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π, {unchanged_count} –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
        
        if len(records_to_insert) == 0 and len(records_to_update) == 0:
            st.success("‚úÖ –ù–∏–∫–∞–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ. –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∞–∫—Ç—É–∞–ª—å–Ω–∞.")
            return True
        
        total_operations = len(records_to_insert) + len(records_to_update)
        total_batches = ((total_operations-1) // batch_size) + 1
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        successful_operations = 0
        current_operation = 0
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏
        if records_to_insert:
            st.info(f"‚ûï –î–æ–±–∞–≤–ª–µ–Ω–∏–µ {len(records_to_insert)} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π...")
            
            for i in range(0, len(records_to_insert), batch_size):
                batch_num = current_operation // batch_size + 1
                batch_end = min(i + batch_size, len(records_to_insert))
                batch_data = records_to_insert[i:batch_end]
                
                try:
                    status_text.text(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞–∫–µ—Ç–∞ {batch_num}: –∑–∞–ø–∏—Å–∏ {i+1}-{batch_end}")
                    
                    result = supabase.table('course_analytics').insert(batch_data).execute()
                    
                    if result.data:
                        successful_operations += len(result.data)
                    
                    current_operation += len(batch_data)
                    progress = current_operation / total_operations
                    progress_bar.progress(progress)
                    
                    time.sleep(0.1)
                    
                except Exception as e:
                    error_msg = str(e)
                    if "row-level security policy" in error_msg.lower() or "42501" in error_msg:
                        st.error(f"‚ùå –ü–∞–∫–µ—Ç {batch_num}: –û—à–∏–±–∫–∞ Row Level Security")
                        st.error("üí° –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å RLS –ø–æ–ª–∏—Ç–∏–∫–∏ –≤ Supabase. –û—Ç–∫–ª—é—á–∏—Ç–µ RLS –∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ –ø–æ–ª–∏—Ç–∏–∫—É —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è.")
                    elif "duplicate key value violates unique constraint" in error_msg.lower() or "23505" in error_msg:
                        st.error(f"‚ùå –ü–∞–∫–µ—Ç {batch_num}: –û—à–∏–±–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–∞ –∫–ª—é—á–∞")
                        st.error("üí° –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã email –≤ –±–∞–∑–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
                        # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫–∞–∂–¥—É—é –∑–∞–ø–∏—Å—å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ
                        st.info("üîÑ –ü–æ–ø—ã—Ç–∫–∞ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø–∏—Å–µ–π...")
                        individual_success = 0
                        for record in batch_data:
                            try:
                                individual_result = supabase.table('course_analytics').insert([record]).execute()
                                if individual_result.data:
                                    individual_success += 1
                            except Exception as individual_error:
                                # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                                pass
                        if individual_success > 0:
                            successful_operations += individual_success
                            st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–æ: {individual_success} –∑–∞–ø–∏—Å–µ–π")
                    else:
                        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –ø–∞–∫–µ—Ç {batch_num}: {error_msg}")
                        return False
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        if records_to_update:
            st.info(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ {len(records_to_update)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π...")
            
            for record in records_to_update:
                try:
                    record_id = record.pop('id')  # –£–¥–∞–ª—è–µ–º ID –∏–∑ –¥–∞–Ω–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                    
                    result = supabase.table('course_analytics').update(record).eq('id', record_id).execute()
                    
                    if result.data:
                        successful_operations += 1
                    
                    current_operation += 1
                    progress = current_operation / total_operations
                    progress_bar.progress(progress)
                    
                    if current_operation % 10 == 0:  # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∫–∞–∂–¥—ã–µ 10 –æ–ø–µ—Ä–∞—Ü–∏–π
                        status_text.text(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {current_operation - len(records_to_insert)}/{len(records_to_update)}")
                    
                except Exception as e:
                    st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å: {str(e)}")
                    return False
        
        progress_bar.progress(1.0)
        status_text.text(f"‚úÖ –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {successful_operations} –æ–ø–µ—Ä–∞—Ü–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
        return True
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è Supabase: {str(e)}")
        return False

def main():
    st.title("üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∫—É—Ä—Å–æ–≤")
    st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –∏ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –∞–Ω–∞–ª–∏—Ç–∏–∫—É –∫—É—Ä—Å–æ–≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ Supabase")
    
    # Sidebar for file uploads
    st.sidebar.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
    
    # –û–ø—Ü–∏—è –≤—ã–±–æ—Ä–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ë–î
    st.sidebar.markdown("---")
    st.sidebar.subheader("üíæ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    use_separated_tables = st.sidebar.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É:",
        ["–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞", "–†–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã"],
        index=1,  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ
        help="–†–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã: —Å—Ç—É–¥–µ–Ω—Ç—ã –æ—Ç–¥–µ–ª—å–Ω–æ, –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ –∫—É—Ä—Å–∞–º –æ—Ç–¥–µ–ª—å–Ω–æ"
    ) == "–†–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã"
    
    if use_separated_tables:
        st.sidebar.info("üîÑ –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã")
    else:
        st.sidebar.info("üîó –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞")
    
    # File upload widgets
    student_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (Excel/CSV)",
        type=['xlsx', 'xls', 'csv'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV —Ñ–∞–π–ª —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç—É–¥–µ–Ω—Ç–∞—Ö"
    )
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("–§–∞–π–ª—ã –∫—É—Ä—Å–æ–≤ (CSV/Excel)")
    
    course_cg_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –¶–ì",
        type=['csv', 'xlsx', 'xls'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª –¥–ª—è –∫—É—Ä—Å–∞ –¶–∏—Ñ—Ä–æ–≤–∞—è –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç—å"
    )
    
    course_python_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ Python",
        type=['csv', 'xlsx', 'xls'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª –¥–ª—è –∫—É—Ä—Å–∞ Python"
    )
    
    course_analysis_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö",
        type=['csv', 'xlsx', 'xls'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª –¥–ª—è –∫—É—Ä—Å–∞ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"
    )
    
    # Main content area
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üìã –°—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        # Check if all files are uploaded
        files_uploaded = all([
            student_file is not None,
            course_cg_file is not None,
            course_python_file is not None,
            course_analysis_file is not None
        ])
        
        if not files_uploaded:
            st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
            st.markdown("""
            - ‚úÖ –°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (Excel –∏–ª–∏ CSV —Ñ–∞–π–ª)
            - ‚úÖ –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –¶–ì (CSV –∏–ª–∏ Excel —Ñ–∞–π–ª)  
            - ‚úÖ –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ Python (CSV –∏–ª–∏ Excel —Ñ–∞–π–ª)
            - ‚úÖ –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (CSV –∏–ª–∏ Excel —Ñ–∞–π–ª)
            """)
            
            # Show upload status
            file_status = {
                "–°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤": "‚úÖ" if student_file else "‚ùå",
                "–ö—É—Ä—Å –¶–ì": "‚úÖ" if course_cg_file else "‚ùå",
                "–ö—É—Ä—Å Python": "‚úÖ" if course_python_file else "‚ùå",
                "–ö—É—Ä—Å –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö": "‚úÖ" if course_analysis_file else "‚ùå"
            }
            
            status_df = pd.DataFrame([{"–§–∞–π–ª": k, "–°—Ç–∞—Ç—É—Å": v} for k, v in file_status.items()])
            st.table(status_df)
        
        else:
            st.success("–í—Å–µ —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –ì–æ—Ç–æ–≤–æ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ.")
            
            if st.button("üöÄ –ù–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É", type="primary"):
                
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                    
                    # Step 0: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase
                    st.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase...")
                    supabase = authenticate_supabase()
                    if supabase is None:
                        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase")
                        st.error("üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–µ–∫—Ä–µ—Ç–æ–≤ –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É")
                        st.stop()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
                    if not check_supabase_connection(supabase):
                        st.error("‚ùå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
                        st.error("üí° –£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–æ—Å—Ç—É–ø–æ–º –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É")
                        st.stop()
                    
                    st.success("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç")
                    
                    # Step 1: Load student list
                    st.info("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤...")
                    student_list = load_student_list(student_file)
                    if student_list is None:
                        st.stop()
                    st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(student_list)} –∑–∞–ø–∏—Å–µ–π —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
                    
                    # Step 2: Process course files
                    st.info("üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –∫—É—Ä—Å–æ–≤...")
                    course_names = ['–¶–ì', '–ü–∏—Ç–æ–Ω', '–ê–Ω–¥–∞–Ω']
                    course_files = [course_cg_file, course_python_file, course_analysis_file]
                    course_data_list = []
                    
                    for course_file, course_name in zip(course_files, course_names):
                        course_data = extract_course_data(course_file, course_name)
                        if course_data is None:
                            st.stop()
                        course_data_list.append(course_data)
                        st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω –∫—É—Ä—Å {course_name}: {len(course_data)} –∑–∞–ø–∏—Å–µ–π")
                    
                    # Step 3: Consolidate data
                    st.info("üîÑ –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
                    consolidated_data = consolidate_data(student_list, course_data_list, course_names)
                    if consolidated_data is None:
                        st.stop()
                    st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã: {len(consolidated_data)} –≤—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π")
                    
                    # Step 4: Show summary statistics table
                    st.info("üìã –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
                    
                    # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
                    summary_data = []
                    for course_name in course_names:
                        col_name = f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'
                        if col_name in consolidated_data.columns:
                            course_data = consolidated_data[col_name].dropna()
                            if len(course_data) > 0:
                                avg_completion = course_data.mean()
                                students_100 = len(course_data[course_data == 100.0])
                                students_0 = len(course_data[course_data == 0.0])
                                students_partial = len(course_data[(course_data > 0.0) & (course_data < 100.0)])
                                total_students = len(course_data)
                                
                                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–±–∏–≤–∫—É –ø–æ 10% –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º
                                students_90_99 = len(course_data[(course_data >= 90.0) & (course_data < 100.0)])
                                students_80_89 = len(course_data[(course_data >= 80.0) & (course_data < 90.0)])
                                students_70_79 = len(course_data[(course_data >= 70.0) & (course_data < 80.0)])
                                students_60_69 = len(course_data[(course_data >= 60.0) & (course_data < 70.0)])
                                students_50_59 = len(course_data[(course_data >= 50.0) & (course_data < 60.0)])
                                students_40_49 = len(course_data[(course_data >= 40.0) & (course_data < 50.0)])
                                students_30_39 = len(course_data[(course_data >= 30.0) & (course_data < 40.0)])
                                students_20_29 = len(course_data[(course_data >= 20.0) & (course_data < 30.0)])
                                students_10_19 = len(course_data[(course_data >= 10.0) & (course_data < 20.0)])
                                students_1_9 = len(course_data[(course_data > 0.0) & (course_data < 10.0)])
                                
                                summary_data.append({
                                    '–ö—É—Ä—Å': course_name,
                                    '–°—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤—Å–µ–≥–æ': total_students,
                                    '–°—Ä–µ–¥–Ω–∏–π %': f"{avg_completion:.1f}%",
                                    '100%': students_100,
                                    '90-99%': students_90_99,
                                    '80-89%': students_80_89,
                                    '70-79%': students_70_79,
                                    '60-69%': students_60_69,
                                    '50-59%': students_50_59,
                                    '40-49%': students_40_49,
                                    '30-39%': students_30_39,
                                    '20-29%': students_20_29,
                                    '10-19%': students_10_19,
                                    '1-9%': students_1_9,
                                    '0%': students_0
                                })
                    
                    if summary_data:
                        summary_df = pd.DataFrame(summary_data)
                        st.subheader("üìã –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ –∫—É—Ä—Å–∞–º")
                        st.table(summary_df)
                        
                        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                        total_students = len(consolidated_data)
                        students_with_data = len(consolidated_data.dropna(subset=[f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_names[0]}', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_names[1]}', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_names[2]}'], how='all'))
                        
                        st.info(f"üìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {total_students} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ —Å–ø–∏—Å–∫–µ, {students_with_data} —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ")
                    
                    # Step 5: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö Supabase
                    st.info("üíæ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö Supabase...")
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
                    
                    if use_separated_tables:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º 4 –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã
                        st.info("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –≤ 4 –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã...")
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
                        if not upload_students_to_supabase(supabase, student_list):
                            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
                            st.stop()
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫—É—Ä—Å—ã
                        if not upload_all_courses_to_supabase(supabase, course_data_list, course_names):
                            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫—É—Ä—Å—ã")
                            st.stop()
                        
                        success = True
                    else:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
                        success = upload_to_supabase(supabase, consolidated_data)
                    
                    if success:
                        st.success("üéâ –í—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                        st.balloons()
                    else:
                        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ Supabase")
    
    with col2:
        st.header("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        
        # –ö–Ω–æ–ø–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        st.subheader("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è")
        if st.button("üîç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Supabase", type="secondary"):
            supabase = authenticate_supabase()
            if supabase:
                check_supabase_connection(supabase)
        
        st.markdown("---")
        st.markdown("""
        **–°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
        - –°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Excel (.xlsx, .xls) –∏–ª–∏ CSV (.csv)
        - –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV (.csv) –∏–ª–∏ Excel (.xlsx, .xls) —Å–æ —Å—Ç–æ–ª–±—Ü–∞–º–∏:
          - `–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞`
          - `–ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è`
        - –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase
        
        **–†–µ–∑—É–ª—å—Ç–∞—Ç:**
        - –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö Supabase
        - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—É–¥–µ–Ω—Ç–∞—Ö —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        - –ù—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤, –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤ –¥–∞–Ω–Ω—ã—Ö –∫—É—Ä—Å–æ–≤
        
        **–≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:**
        1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        2. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–µ—Ö —Ñ–∞–π–ª–æ–≤ –∫—É—Ä—Å–æ–≤
        3. –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ email
        4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        5. –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö Supabase
        
        **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏:**
        - UTF-8 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        - UTF-16 —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º —Ç–∞–±—É–ª—è—Ü–∏–∏
        - CP1251 (–¥–ª—è —Ä—É—Å—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤)
        """)
        
        if files_uploaded:
            st.markdown("---")
            st.success("–ì–æ—Ç–æ–≤–æ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ!")

if __name__ == "__main__":
    main()

