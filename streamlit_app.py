"""
Streamlit Application for Course Analytics Processing
Upload files and process course data automatically with Supabase database
"""

import streamlit as st
import pandas as pd
from supabase import create_client, Client
import os
import tempfile
import time
from io import StringIO
from datetime import datetime

# Page configuration
st.set_page_config(
    page_title="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∫—É—Ä—Å–æ–≤ - Supabase",
    page_icon="üìä",
    layout="wide"
)

def authenticate_supabase():
    """–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Å Supabase –∏—Å–ø–æ–ª—å–∑—É—è Streamlit secrets"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–µ–∫—Ä–µ—Ç–æ–≤ Supabase
        if not hasattr(st, 'secrets') or "supabase" not in st.secrets:
            st.error("‚ùå –°–µ–∫—Ä–µ—Ç—ã Supabase –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Streamlit")
            st.error("üí° –î–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ —Å–µ–∫—Ä–µ—Ç—ã SUPABASE_URL –∏ SUPABASE_KEY")
            return None
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∏–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤
        supabase_url = st.secrets["supabase"]["url"]
        supabase_key = st.secrets["supabase"]["key"]
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–∞ Supabase
        supabase: Client = create_client(supabase_url, supabase_key)
        
        st.success("‚úÖ –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è Supabase —É—Å–ø–µ—à–Ω–∞")
        return supabase
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ Supabase: {str(e)}")
        return None

def check_supabase_connection(supabase):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase"""
    try:
        if supabase is None:
            st.error("‚ùå –ö–ª–∏–µ–Ω—Ç Supabase –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return False
        
        st.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ course_analytics
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å —Å—Ö–µ–º—É —Ç–∞–±–ª–∏—Ü—ã
            result = supabase.table('course_analytics').select('*').limit(1).execute()
            st.success("‚úÖ –¢–∞–±–ª–∏—Ü–∞ 'course_analytics' –¥–æ—Å—Ç—É–ø–Ω–∞")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–æ–ª–æ–Ω–∫–∞ "–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã"
            if result.data:
                # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                sample_record = result.data[0]
                if '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã' not in sample_record:
                    st.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –î–æ–±–∞–≤–ª—è–µ–º...")
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â—É—é –∫–æ–ª–æ–Ω–∫—É
                    alter_sql = """
                    ALTER TABLE course_analytics 
                    ADD COLUMN IF NOT EXISTS –≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã TEXT;
                    """
                    try:
                        alter_result = supabase.rpc('exec_sql', {'sql': alter_sql}).execute()
                        st.success("‚úÖ –ö–æ–ª–æ–Ω–∫–∞ '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã' –¥–æ–±–∞–≤–ª–µ–Ω–∞")
                    except Exception as alter_error:
                        st.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É: {str(alter_error)}")
                        st.info("üí° –í—ã–ø–æ–ª–Ω–∏—Ç–µ –≤ Supabase SQL Editor:")
                        st.code(alter_sql, language='sql')
                else:
                    st.success("‚úÖ –ö–æ–ª–æ–Ω–∫–∞ '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã' –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –Ω–∞ –∑–∞–ø–∏—Å—å (—Ç–µ—Å—Ç–æ–≤–∞—è –∑–∞–ø–∏—Å—å)
            test_record = {
                '—Ñ–∏–æ': f'–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è {datetime.now().strftime("%H:%M:%S")}',
                '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞': 'test@connection.check',
                '—Ñ–∏–ª–∏–∞–ª_–∫–∞–º–ø—É—Å': '–¢–µ—Å—Ç',
                '—Ñ–∞–∫—É–ª—å—Ç–µ—Ç': '–¢–µ—Å—Ç',
                '–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_–ø—Ä–æ–≥—Ä–∞–º–º–∞': '–¢–µ—Å—Ç',
                '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã': '–¢–µ—Å—Ç',
                '–≥—Ä—É–ø–ø–∞': '–¢–µ—Å—Ç',
                '–∫—É—Ä—Å': '–¢–µ—Å—Ç',
                '–ø—Ä–æ—Ü–µ–Ω—Ç_—Ü–≥': 0.0,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_–ø–∏—Ç–æ–Ω': 0.0,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_–∞–Ω–¥–∞–Ω': 0.0,
                'created_at': datetime.now().isoformat()
            }
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∑–∞–ø–∏—Å—å
            insert_result = supabase.table('course_analytics').insert(test_record).execute()
            
            if insert_result.data:
                test_id = insert_result.data[0]['id']
                st.success("‚úÖ –ü—Ä–∞–≤–∞ –Ω–∞ –∑–∞–ø–∏—Å—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã")
                
                # –£–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∑–∞–ø–∏—Å—å
                supabase.table('course_analytics').delete().eq('id', test_id).execute()
                st.success("‚úÖ –ü—Ä–∞–≤–∞ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω—ã")
            else:
                st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")
                return False
                
        except Exception as e:
            if "relation \"course_analytics\" does not exist" in str(e).lower():
                st.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ 'course_analytics' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –ë—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                if not create_course_analytics_table(supabase):
                    return False
            elif "row-level security policy" in str(e).lower() or "42501" in str(e):
                st.error("‚ùå –û—à–∏–±–∫–∞ Row Level Security (RLS): –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –ø–æ–ª–∏—Ç–∏–∫–∞–º–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
                st.error("üí° –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å RLS –ø–æ–ª–∏—Ç–∏–∫–∏ –≤ Supabase Dashboard:")
                st.code("""
-- –í Supabase SQL Editor –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:

-- 1. –û—Ç–∫–ª—é—á–∏—Ç—å RLS –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π)
ALTER TABLE course_analytics DISABLE ROW LEVEL SECURITY;

-- –ò–õ–ò

-- 2. –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–∏—Ç–∏–∫—É –¥–ª—è —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π (–±–æ–ª–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
CREATE POLICY "Enable all operations for service role" ON course_analytics
FOR ALL USING (true) WITH CHECK (true);

-- 3. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ: –ø–æ–ª–∏—Ç–∏–∫–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è authenticated –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
CREATE POLICY "Enable operations for authenticated users" ON course_analytics
FOR ALL USING (auth.role() = 'authenticated') WITH CHECK (auth.role() = 'authenticated');
                """, language='sql')
                return False
            else:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ç–∞–±–ª–∏—Ü–µ: {str(e)}")
                return False
        
        st.success("üéâ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ!")
        return True
        
    except Exception as e:
        st.error(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {str(e)}")
        return False

def create_course_analytics_table(supabase):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã course_analytics –≤ Supabase"""
    try:
        st.info("üîß –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã course_analytics...")
        
        # SQL –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
        create_table_sql = """
        CREATE TABLE IF NOT EXISTS course_analytics (
            id SERIAL PRIMARY KEY,
            —Ñ–∏–æ TEXT NOT NULL,
            –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞ TEXT UNIQUE NOT NULL,
            —Ñ–∏–ª–∏–∞–ª_–∫–∞–º–ø—É—Å TEXT,
            —Ñ–∞–∫—É–ª—å—Ç–µ—Ç TEXT,
            –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_–ø—Ä–æ–≥—Ä–∞–º–º–∞ TEXT,
            –≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã TEXT,
            –≥—Ä—É–ø–ø–∞ TEXT,
            –∫—É—Ä—Å TEXT,
            –ø—Ä–æ—Ü–µ–Ω—Ç_—Ü–≥ REAL DEFAULT 0.0,
            –ø—Ä–æ—Ü–µ–Ω—Ç_–ø–∏—Ç–æ–Ω REAL DEFAULT 0.0,
            –ø—Ä–æ—Ü–µ–Ω—Ç_–∞–Ω–¥–∞–Ω REAL DEFAULT 0.0,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
            updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
        );
        
        -- –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –Ω–∞ email –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        CREATE INDEX IF NOT EXISTS idx_course_analytics_email 
        ON course_analytics(–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞);
        
        -- –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è updated_at
        CREATE OR REPLACE FUNCTION update_updated_at_column()
        RETURNS TRIGGER AS $$
        BEGIN
            NEW.updated_at = NOW();
            RETURN NEW;
        END;
        $$ language 'plpgsql';
        
        -- –¢—Ä–∏–≥–≥–µ—Ä –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è updated_at
        DROP TRIGGER IF EXISTS update_course_analytics_updated_at ON course_analytics;
        CREATE TRIGGER update_course_analytics_updated_at
            BEFORE UPDATE ON course_analytics
            FOR EACH ROW
            EXECUTE FUNCTION update_updated_at_column();
        """
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º SQL —á–µ—Ä–µ–∑ RPC (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è) –∏–ª–∏ —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å
        try:
            result = supabase.rpc('exec_sql', {'sql': create_table_sql}).execute()
            st.success("‚úÖ –¢–∞–±–ª–∏—Ü–∞ course_analytics —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return True
        except Exception as rpc_error:
            st.warning(f"‚ö†Ô∏è RPC –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {str(rpc_error)}")
            st.info("üí° –°–æ–∑–¥–∞–π—Ç–µ —Ç–∞–±–ª–∏—Ü—É course_analytics –≤—Ä—É—á–Ω—É—é –≤ Supabase Dashboard")
            st.code(create_table_sql, language='sql')
            return False
            
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã: {str(e)}")
        return False

def load_student_list(uploaded_file):
    """Load student list from uploaded Excel or CSV file"""
    try:
        # Determine file type and load accordingly
        file_name = uploaded_file.name.lower()
        if file_name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        elif file_name.endswith('.csv'):
            # Check encoding and try different options
            content = uploaded_file.getvalue()
            try:
                # Try UTF-16 with tab delimiter first (based on project memory)
                df = pd.read_csv(StringIO(content.decode('utf-16')), sep='\t')
            except (UnicodeDecodeError, pd.errors.ParserError):
                try:
                    # Try UTF-8 with comma delimiter
                    df = pd.read_csv(StringIO(content.decode('utf-8')))
                except UnicodeDecodeError:
                    # Try cp1251 encoding (common for Russian files)
                    df = pd.read_csv(StringIO(content.decode('cp1251')))
        else:
            st.error("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Excel (.xlsx, .xls) –∏–ª–∏ CSV (.csv)")
            return None
        
        # Map columns to required format
        required_columns = {
            '–§–ò–û': ['—Ñ–∏–æ', '—Ñio', '–∏–º—è', 'name'],
            '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞': ['–∞–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', 'email', '–ø–æ—á—Ç–∞', 'e-mail'],
            '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)': ['—Ñ–∏–ª–∏–∞–ª', '–∫–∞–º–ø—É—Å', 'campus'],
            '–§–∞–∫—É–ª—å—Ç–µ—Ç': ['—Ñ–∞–∫—É–ª—å—Ç–µ—Ç', 'faculty'],
            '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞': ['–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ø—Ä–æ–≥—Ä–∞–º–º–∞', 'educational program'],
            '–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã': ['–≤–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '–≤–µ—Ä—Å–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã', 'program version', 'version'],
            '–ì—Ä—É–ø–ø–∞': ['–≥—Ä—É–ø–ø–∞', 'group'],
            '–ö—É—Ä—Å': ['–∫—É—Ä—Å', 'course']
        }
        
        # Find matching columns in the file
        found_columns = {}
        df_columns_lower = [str(col).lower().strip() for col in df.columns]
        
        for target_col, possible_names in required_columns.items():
            for col_idx, col_name in enumerate(df_columns_lower):
                if any(possible_name in col_name for possible_name in possible_names):
                    found_columns[target_col] = df.columns[col_idx]
                    break
        
        # Create new DataFrame with required columns
        result_df = pd.DataFrame()
        for target_col, source_col in found_columns.items():
            if source_col in df.columns:
                result_df[target_col] = df[source_col]
        
        # Check for '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ' column and parse it according to specification
        if '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ' in df.columns:
            user_data = df['–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ'].astype(str)
            parsed_data = user_data.str.split(';', expand=True)
            if len(parsed_data.columns) >= 4:
                result_df['–§–∞–∫—É–ª—å—Ç–µ—Ç'] = parsed_data[0]
                result_df['–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞'] = parsed_data[1] 
                result_df['–ö—É—Ä—Å'] = parsed_data[2]
                result_df['–ì—Ä—É–ø–ø–∞'] = parsed_data[3]
        
        # Add missing columns with empty values
        for required_col in required_columns.keys():
            if required_col not in result_df.columns:
                result_df[required_col] = ''
        
        # Filter only students with edu.hse.ru email
        if '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞' in result_df.columns:
            result_df = result_df[result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'].astype(str).str.contains('@edu.hse.ru', na=False)]
            result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'] = pd.Series(result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞']).astype(str).str.lower().str.strip()
        
        return result_df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {str(e)}")
        return None

def extract_course_data(uploaded_file, course_name):
    """Extract email and completion percentage from uploaded course file (CSV or Excel)"""
    try:
        # Determine file type and load accordingly
        file_name = uploaded_file.name.lower()
        if file_name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        elif file_name.endswith('.csv'):
            # Read the uploaded file with different encoding options
            content = uploaded_file.getvalue()
            try:
                # Try UTF-16 with tab delimiter first (based on project memory)
                df = pd.read_csv(StringIO(content.decode('utf-16')), sep='\t')
            except (UnicodeDecodeError, pd.errors.ParserError):
                try:
                    # Try UTF-8 with comma delimiter
                    df = pd.read_csv(StringIO(content.decode('utf-8')))
                except UnicodeDecodeError:
                    # Try cp1251 encoding (common for Russian files)
                    df = pd.read_csv(StringIO(content.decode('cp1251')))
        else:
            st.error(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Excel (.xlsx, .xls) –∏–ª–∏ CSV (.csv)")
            return None
        
        # Look for email column with different possible names
        email_column = None
        possible_email_names = ['–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', 'Email', '–ü–æ—á—Ç–∞', 'E-mail']
        
        for col_name in possible_email_names:
            if col_name in df.columns:
                email_column = col_name
                break
        
        if email_column is None:
            st.error(f"–°—Ç–æ–ª–±–µ—Ü —Å email –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ {course_name}. –û–∂–∏–¥–∞—é—Ç—Å—è —Å—Ç–æ–ª–±—Ü—ã: {', '.join(possible_email_names)}")
            return None
        
        # Look for completion percentage column
        completion_column = None
        possible_completion_names = ['–ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è', 'Completion', 'Progress', '–ü—Ä–æ–≥—Ä–µ—Å—Å', '–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ']
        
        # Also check if we need to calculate completion from multiple columns
        # Look for columns that might contain completion data
        completed_columns = []
        timestamp_columns = []
        
        for col in df.columns:
            if col not in ['Unnamed: 0', email_column, '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ', 'User information', '–°—Ç—Ä–∞–Ω–∞']:
                # Check if this column contains completion data
                if not col.startswith('Unnamed:') and len(str(col).strip()) > 0:
                    # Sample some values to see if they contain "–í—ã–ø–æ–ª–Ω–µ–Ω–æ" –∏–ª–∏ "–ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ"
                    sample_values = df[col].dropna().astype(str).head(100)
                    if any('–í—ã–ø–æ–ª–Ω–µ–Ω–æ' in str(val) or '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ' in str(val).lower() for val in sample_values):
                        # Skip informational columns (based on experience memory)
                        if not all(str(val) == '–ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ' for val in sample_values if pd.notna(val)):
                            completed_columns.append(col)
                elif col.startswith('Unnamed:') and col != 'Unnamed: 0':
                    # Check if this unnamed column contains timestamps (completion indicators)
                    sample_values = df[col].dropna().astype(str).head(20)
                    for val in sample_values:
                        val_str = str(val).strip()
                        # Check if it looks like a timestamp
                        if any(pattern in val_str for pattern in ['2020', '2021', '2022', '2023', '2024']) and ':' in val_str:
                            timestamp_columns.append(col)
                            break
        
        # If we found timestamp columns, use them for completion calculation
        if timestamp_columns:
            st.info(f"–ù–∞–π–¥–µ–Ω–æ {len(timestamp_columns)} —Å—Ç–æ–ª–±—Ü–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            
            # Calculate completion percentage based on timestamps
            completion_data = []
            for idx, row in df.iterrows():
                email_val = row[email_column]
                if pd.isna(email_val) or '@edu.hse.ru' not in str(email_val).lower():
                    continue
                
                total_tasks = len(timestamp_columns)
                completed_tasks = 0
                
                for col in timestamp_columns:
                    cell_val = row[col]
                    val_str = str(cell_val).strip() if not pd.isna(cell_val) else ''
                    # Check if there's a valid timestamp (indicates completion)
                    if val_str and val_str != 'nan' and val_str != '':
                        # Verify it looks like a timestamp
                        if any(pattern in val_str for pattern in ['2020', '2021', '2022', '2023', '2024']) and ':' in val_str:
                            completed_tasks += 1
                
                # Calculate percentage
                percentage = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                completion_data.append({'email': str(email_val).lower().strip(), 'percentage': percentage})
            
            # Create result DataFrame
            if completion_data:
                result_df = pd.DataFrame(completion_data)
                result_df.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
                st.success(f"‚úÖ –†–∞—Å—Å—á–∏—Ç–∞–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è {len(result_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫—É—Ä—Å–∞ {course_name} –Ω–∞ –æ—Å–Ω–æ–≤–µ {len(timestamp_columns)} –∑–∞–¥–∞–Ω–∏–π")
                return result_df
            else:
                st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
                return None
        
        # If we found completion tracking columns, calculate percentage
        elif completed_columns:
            st.info(f"–ù–∞–π–¥–µ–Ω–æ {len(completed_columns)} —Å—Ç–æ–ª–±—Ü–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            
            # Calculate completion percentage
            completion_data = []
            for idx, row in df.iterrows():
                email_val = row[email_column]
                if pd.isna(email_val) or '@edu.hse.ru' not in str(email_val).lower():
                    continue
                
                total_tasks = 0
                completed_tasks = 0
                
                for col in completed_columns:
                    cell_val = row[col]
                    val = str(cell_val).strip() if not pd.isna(cell_val) else ''
                    if val and val != 'nan':
                        total_tasks += 1
                        if '–í—ã–ø–æ–ª–Ω–µ–Ω–æ' in val or '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ' in val.lower():
                            completed_tasks += 1
                
                # Calculate percentage
                percentage = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                completion_data.append({'email': str(email_val).lower().strip(), 'percentage': percentage})
            
            # Create result DataFrame
            if completion_data:
                result_df = pd.DataFrame(completion_data)
                result_df.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
                st.success(f"‚úÖ –†–∞—Å—Å—á–∏—Ç–∞–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è {len(result_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫—É—Ä—Å–∞ {course_name}")
                return result_df
            else:
                st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
                return None
        
        # Fallback: look for direct completion percentage column
        for col_name in possible_completion_names:
            if col_name in df.columns:
                completion_column = col_name
                break
        
        if completion_column is None:
            st.error(f"–°—Ç–æ–ª–±–µ—Ü —Å –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ {course_name}. –û–∂–∏–¥–∞—é—Ç—Å—è —Å—Ç–æ–ª–±—Ü—ã: {', '.join(possible_completion_names)}")
            st.info(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {', '.join([col for col in df.columns[:10]])}")
            return None
        
        # Extract the specific columns we need
        course_data = df[[email_column, completion_column]].copy()
        course_data.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
        course_data['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'] = pd.Series(course_data['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞']).astype(str).str.lower().str.strip()
        
        # Filter only edu.hse.ru emails
        email_series = pd.Series(course_data['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'])
        course_data = course_data[email_series.str.contains('@edu.hse.ru', na=False)]
        
        return course_data
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫—É—Ä—Å–∞ {course_name}: {str(e)}")
        return None

def consolidate_data(student_list, course_data_list, course_names):
    """Consolidate all course data with student list and deduplication"""
    try:
        # Start with student list
        consolidated = student_list.copy()
        
        # Merge each course data
        for course_data, course_name in zip(course_data_list, course_names):
            if course_data is not None:
                consolidated = pd.merge(consolidated, course_data, on='–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', how='left')
                # –ó–∞–ø–æ–ª–Ω—è–µ–º NULL –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–µ 0.0)
                consolidated[f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'] = consolidated[f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'].where(pd.notna(consolidated[f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']), None)
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ email
        st.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        initial_count = len(consolidated)
        email_counts = consolidated['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'].value_counts()
        duplicates = email_counts[email_counts > 1]
        
        if len(duplicates) > 0:
            st.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(duplicates)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ email:")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            duplicate_list = list(duplicates.index[:5])
            for email in duplicate_list:
                count = duplicates[email]
                st.text(f"  - {email}: {count} –∑–∞–ø–∏—Å–µ–π")
            if len(duplicates) > 5:
                st.text(f"  ... –∏ –µ—â—ë {len(duplicates) - 5} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, –æ—Å—Ç–∞–≤–ª—è—è –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ
        consolidated = consolidated.drop_duplicates(subset=['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'], keep='first')
        
        final_count = len(consolidated)
        removed_count = initial_count - final_count
        
        if removed_count > 0:
            st.success(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤. –û—Å—Ç–∞–ª–æ—Å—å {final_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
        else:
            st.success(f"‚úÖ –î—É–±–ª–∏–∫–∞—Ç—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã. –í—Å–µ–≥–æ {final_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π")
        
        return consolidated
        
    except Exception as e:
        st.error(f"Error consolidating data: {str(e)}")
        return None

def upload_to_supabase(supabase, data_df, batch_size=200):
    """–ü—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Supabase —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º upsert"""
    try:
        st.info("üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏...")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è upsert
        records_to_upsert = []
        processed_emails = set()  # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ email –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        
        for _, row in data_df.iterrows():
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ email
            email = str(row.get('–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', '')).strip().lower()
            if not email:  # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                email = str(row.get('–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', '')).strip().lower()
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å–∏ –±–µ–∑ email –∏–ª–∏ —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –¥–æ–º–µ–Ω–æ–º
            if not email or '@edu.hse.ru' not in email:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ —Ç–µ–∫—É—â–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö
            if email in processed_emails:
                continue
            processed_emails.add(email)
            
            # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–µ–Ω—É–ª–µ–≤–æ–µ –§–ò–û: –±–µ—Ä–µ–º –∏–∑ –¥–∞–Ω–Ω—ã—Ö, –∏–Ω–∞—á–µ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –∏–∑ email
            raw_name = row.get('–§–ò–û')
            name_str = ''
            if pd.notna(raw_name):
                name_str = str(raw_name).strip()
            if not name_str:
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–∑ email (–¥–æ @), –∑–∞–º–µ–Ω—è—è —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É—è —Ä–µ–≥–∏—Å—Ç—Ä
                email_prefix = email.split('@')[0] if email else ''
                normalized = email_prefix.replace('.', ' ').replace('_', ' ').strip()
                name_str = normalized.title() if normalized else email
            # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –∏—Å–∫–ª—é—á–∞–µ–º None: –ë–î —Ç—Ä–µ–±—É–µ—Ç NOT NULL
            if name_str is None:
                name_str = ''

            record = {
                '—Ñ–∏–æ': name_str,
                '–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞': email,
                '—Ñ–∏–ª–∏–∞–ª_–∫–∞–º–ø—É—Å': str(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)', '')) if pd.notna(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)')) and str(row.get('–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)', '')).strip() else None,
                '—Ñ–∞–∫—É–ª—å—Ç–µ—Ç': str(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç', '')) if pd.notna(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç')) and str(row.get('–§–∞–∫—É–ª—å—Ç–µ—Ç', '')).strip() else None,
                '–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è_–ø—Ä–æ–≥—Ä–∞–º–º–∞': str(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '')) if pd.notna(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞')) and str(row.get('–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '')).strip() else None,
                '–≤–µ—Ä—Å–∏—è_–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π_–ø—Ä–æ–≥—Ä–∞–º–º—ã': str(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '')) if pd.notna(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã')) and str(row.get('–í–µ—Ä—Å–∏—è –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã', '')).strip() else None,
                '–≥—Ä—É–ø–ø–∞': str(row.get('–ì—Ä—É–ø–ø–∞', '')) if pd.notna(row.get('–ì—Ä—É–ø–ø–∞')) and str(row.get('–ì—Ä—É–ø–ø–∞', '')).strip() else None,
                '–∫—É—Ä—Å': str(row.get('–ö—É—Ä—Å', '')) if pd.notna(row.get('–ö—É—Ä—Å')) and str(row.get('–ö—É—Ä—Å', '')).strip() else None,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_—Ü–≥': float(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–¶–ì', 0.0)) if pd.notna(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–¶–ì')) and row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–¶–ì') != '' else None,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_–ø–∏—Ç–æ–Ω': float(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ü–∏—Ç–æ–Ω', 0.0)) if pd.notna(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ü–∏—Ç–æ–Ω')) and row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ü–∏—Ç–æ–Ω') != '' else None,
                '–ø—Ä–æ—Ü–µ–Ω—Ç_–∞–Ω–¥–∞–Ω': float(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ê–Ω–¥–∞–Ω', 0.0)) if pd.notna(row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ê–Ω–¥–∞–Ω')) and row.get('–ü—Ä–æ—Ü–µ–Ω—Ç_–ê–Ω–¥–∞–Ω') != '' else None,
                'updated_at': datetime.now().isoformat()
            }
            
            records_to_upsert.append(record)
        
        st.success(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(records_to_upsert)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
        
        if len(records_to_upsert) == 0:
            st.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
            return True
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç–∞–º–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º upsert
        total_batches = ((len(records_to_upsert)-1) // batch_size) + 1
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        successful_operations = 0
        
        st.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ {len(records_to_upsert)} –∑–∞–ø–∏—Å–µ–π –ø–∞–∫–µ—Ç–∞–º–∏ –ø–æ {batch_size}...")
        
        for i in range(0, len(records_to_upsert), batch_size):
            batch_num = i // batch_size + 1
            batch_end = min(i + batch_size, len(records_to_upsert))
            batch_data = records_to_upsert[i:batch_end]
            
            try:
                status_text.text(f"–ü–∞–∫–µ—Ç {batch_num}/{total_batches}: –∑–∞–ø–∏—Å–∏ {i+1}-{batch_end}")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º upsert - –µ—Å–ª–∏ –∑–∞–ø–∏—Å—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è, –µ—Å–ª–∏ –Ω–µ—Ç - —Å–æ–∑–¥–∞–µ—Ç—Å—è
                result = supabase.table('course_analytics').upsert(batch_data, on_conflict='–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è_–ø–æ—á—Ç–∞').execute()
                
                if result.data:
                    successful_operations += len(result.data)
                
                progress = (i + len(batch_data)) / len(records_to_upsert)
                progress_bar.progress(progress)
                
                time.sleep(0.1)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏
                
            except Exception as e:
                error_msg = str(e)
                if "row-level security policy" in error_msg.lower() or "42501" in error_msg:
                    st.error(f"‚ùå –ü–∞–∫–µ—Ç {batch_num}: –û—à–∏–±–∫–∞ Row Level Security")
                    st.error("üí° –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å RLS –ø–æ–ª–∏—Ç–∏–∫–∏ –≤ Supabase. –û—Ç–∫–ª—é—á–∏—Ç–µ RLS –∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ –ø–æ–ª–∏—Ç–∏–∫—É —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è.")
                    return False
                else:
                    st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø–∞–∫–µ—Ç–µ {batch_num}: {error_msg}")
                    return False
        
        progress_bar.progress(1.0)
        status_text.text(f"‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {successful_operations} –∑–∞–ø–∏—Å–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")
        
        st.success("üéâ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ Supabase!")
        return True
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Supabase: {str(e)}")
        return False

def main():
    st.title("üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∫—É—Ä—Å–æ–≤")
    st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –∏ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –∞–Ω–∞–ª–∏—Ç–∏–∫—É –∫—É—Ä—Å–æ–≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ Supabase")
    
    # Sidebar for file uploads
    st.sidebar.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
    
    # File upload widgets
    student_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (Excel/CSV)",
        type=['xlsx', 'xls', 'csv'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV —Ñ–∞–π–ª —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç—É–¥–µ–Ω—Ç–∞—Ö"
    )
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("–§–∞–π–ª—ã –∫—É—Ä—Å–æ–≤ (CSV/Excel)")
    
    course_cg_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –¶–ì",
        type=['csv', 'xlsx', 'xls'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª –¥–ª—è –∫—É—Ä—Å–∞ –¶–∏—Ñ—Ä–æ–≤–∞—è –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç—å"
    )
    
    course_python_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ Python",
        type=['csv', 'xlsx', 'xls'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª –¥–ª—è –∫—É—Ä—Å–∞ Python"
    )
    
    course_analysis_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö",
        type=['csv', 'xlsx', 'xls'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª –¥–ª—è –∫—É—Ä—Å–∞ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"
    )
    
    # Main content area
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üìã –°—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        # Check if all files are uploaded
        files_uploaded = all([
            student_file is not None,
            course_cg_file is not None,
            course_python_file is not None,
            course_analysis_file is not None
        ])
        
        if not files_uploaded:
            st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
            st.markdown("""
            - ‚úÖ –°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (Excel –∏–ª–∏ CSV —Ñ–∞–π–ª)
            - ‚úÖ –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –¶–ì (CSV –∏–ª–∏ Excel —Ñ–∞–π–ª)  
            - ‚úÖ –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ Python (CSV –∏–ª–∏ Excel —Ñ–∞–π–ª)
            - ‚úÖ –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (CSV –∏–ª–∏ Excel —Ñ–∞–π–ª)
            """)
            
            # Show upload status
            file_status = {
                "–°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤": "‚úÖ" if student_file else "‚ùå",
                "–ö—É—Ä—Å –¶–ì": "‚úÖ" if course_cg_file else "‚ùå",
                "–ö—É—Ä—Å Python": "‚úÖ" if course_python_file else "‚ùå",
                "–ö—É—Ä—Å –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö": "‚úÖ" if course_analysis_file else "‚ùå"
            }
            
            status_df = pd.DataFrame([{"–§–∞–π–ª": k, "–°—Ç–∞—Ç—É—Å": v} for k, v in file_status.items()])
            st.table(status_df)
        
        else:
            st.success("–í—Å–µ —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –ì–æ—Ç–æ–≤–æ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ.")
            
            if st.button("üöÄ –ù–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É", type="primary"):
                
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                    
                    # Step 0: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase
                    st.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase...")
                    supabase = authenticate_supabase()
                    if supabase is None:
                        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase")
                        st.error("üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–µ–∫—Ä–µ—Ç–æ–≤ –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É")
                        st.stop()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
                    if not check_supabase_connection(supabase):
                        st.error("‚ùå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
                        st.error("üí° –£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–æ—Å—Ç—É–ø–æ–º –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É")
                        st.stop()
                    
                    st.success("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç")
                    
                    # Step 1: Load student list
                    st.info("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤...")
                    student_list = load_student_list(student_file)
                    if student_list is None:
                        st.stop()
                    st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(student_list)} –∑–∞–ø–∏—Å–µ–π —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
                    
                    # Step 2: Process course files
                    st.info("üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –∫—É—Ä—Å–æ–≤...")
                    course_names = ['–¶–ì', '–ü–∏—Ç–æ–Ω', '–ê–Ω–¥–∞–Ω']
                    course_files = [course_cg_file, course_python_file, course_analysis_file]
                    course_data_list = []
                    
                    for course_file, course_name in zip(course_files, course_names):
                        course_data = extract_course_data(course_file, course_name)
                        if course_data is None:
                            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É:
                            # —Å–æ–∑–¥–∞—ë–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä —Å email –∏–∑ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∏ NULL –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º
                            st.warning(f"‚ö†Ô∏è –í —Ñ–∞–π–ª–µ –∫—É—Ä—Å–∞ {course_name} –Ω–µ –Ω–∞–π–¥–µ–Ω —Å—Ç–æ–ª–±–µ—Ü —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º. –ë—É–¥—É—Ç –ø–æ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.")
                            placeholder = pd.DataFrame({
                                '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞': student_list['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'].astype(str).str.lower().str.strip(),
                                f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}': [None] * len(student_list)
                            })
                            course_data = placeholder
                        course_data_list.append(course_data)
                        st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω –∫—É—Ä—Å {course_name}: {len(course_data)} –∑–∞–ø–∏—Å–µ–π")
                    
                    # Step 3: Consolidate data
                    st.info("üîÑ –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
                    consolidated_data = consolidate_data(student_list, course_data_list, course_names)
                    if consolidated_data is None:
                        st.stop()
                    st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã: {len(consolidated_data)} –≤—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π")
                    
                    # Step 4: Show statistics
                    st.info("üìà –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
                    stats_col1, stats_col2, stats_col3 = st.columns(3)
                    
                    for i, course_name in enumerate(course_names):
                        col_name = f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'
                        if col_name in consolidated_data.columns:
                            avg_completion = consolidated_data[col_name].mean()
                            students_100 = len(consolidated_data[consolidated_data[col_name] == 100.0])
                            students_0 = len(consolidated_data[consolidated_data[col_name] == 0.0])
                            
                            with [stats_col1, stats_col2, stats_col3][i]:
                                st.metric(
                                    label=f"–ö—É—Ä—Å {course_name}",
                                    value=f"{avg_completion:.2f}%",
                                    delta=f"100%: {students_100} | 0%: {students_0}"
                                )
                    
                    # Step 5: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö Supabase
                    st.info("üíæ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö Supabase...")
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
                    
                    success = upload_to_supabase(supabase, consolidated_data)
                    if success:
                        st.success("üéâ –í—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                        st.balloons()
                    else:
                        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ Supabase")
    
    with col2:
        st.header("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        
        # –ö–Ω–æ–ø–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        st.subheader("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è")
        if st.button("üîç –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Supabase", type="secondary"):
            supabase = authenticate_supabase()
            if supabase:
                check_supabase_connection(supabase)
        
        st.markdown("---")
        st.markdown("""
        **–°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
        - –°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Excel (.xlsx, .xls) –∏–ª–∏ CSV (.csv)
        - –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV (.csv) –∏–ª–∏ Excel (.xlsx, .xls) —Å–æ —Å—Ç–æ–ª–±—Ü–∞–º–∏:
          - `–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞`
          - `–ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è`
        - –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase
        
        **–†–µ–∑—É–ª—å—Ç–∞—Ç:**
        - –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö Supabase
        - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—É–¥–µ–Ω—Ç–∞—Ö —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        - –ù—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤, –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤ –¥–∞–Ω–Ω—ã—Ö –∫—É—Ä—Å–æ–≤
        
        **–≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:**
        1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        2. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–µ—Ö —Ñ–∞–π–ª–æ–≤ –∫—É—Ä—Å–æ–≤
        3. –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ email
        4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        5. –ó–∞–≥—Ä—É–∑–∫–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö Supabase
        
        **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏:**
        - UTF-8 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        - UTF-16 —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º —Ç–∞–±—É–ª—è—Ü–∏–∏
        - CP1251 (–¥–ª—è —Ä—É—Å—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤)
        """)
        
        if files_uploaded:
            st.markdown("---")
            st.success("–ì–æ—Ç–æ–≤–æ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ!")

if __name__ == "__main__":
    main()

