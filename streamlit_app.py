"""
Streamlit Application for Course Analytics Processing
Upload files and process course data automatically
"""

import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
import os
import tempfile
import time
from io import StringIO

# Page configuration
st.set_page_config(
    page_title="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∫—É—Ä—Å–æ–≤",
    page_icon="üìä",
    layout="wide"
)

def get_gcp_credentials():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç GCP credentials —Ç–æ–ª—å–∫–æ –∏–∑ secrets.toml
    """
    if "gcp_service_account" in st.secrets:
        credentials_info = st.secrets["gcp_service_account"]
        return service_account.Credentials.from_service_account_info(credentials_info)
    else:
        raise RuntimeError("‚ùå –ù–µ—Ç —Å–µ–∫—Ä–µ—Ç–∞ [gcp_service_account] –≤ .streamlit/secrets.toml")

def authenticate_google_sheets():
    """
    –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∏ –≤–æ–∑–≤—Ä–∞—Ç –∫–ª–∏–µ–Ω—Ç–∞ gspread
    """
    try:
        creds = get_gcp_credentials()
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ Google Sheets: {str(e)}")
        return None

def load_student_list(uploaded_file):
    """Load student list from uploaded Excel or CSV file"""
    try:
        # Determine file type and load accordingly
        file_name = uploaded_file.name.lower()
        if file_name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        elif file_name.endswith('.csv'):
            # Check encoding and try different options
            content = uploaded_file.getvalue()
            try:
                # Try UTF-16 with tab delimiter first (based on project memory)
                df = pd.read_csv(StringIO(content.decode('utf-16')), sep='\t')
            except (UnicodeDecodeError, pd.errors.ParserError):
                try:
                    # Try UTF-8 with comma delimiter
                    df = pd.read_csv(StringIO(content.decode('utf-8')))
                except UnicodeDecodeError:
                    # Try cp1251 encoding (common for Russian files)
                    df = pd.read_csv(StringIO(content.decode('cp1251')))
        else:
            st.error("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Excel (.xlsx, .xls) –∏–ª–∏ CSV (.csv)")
            return None
        
        # Map columns to required format
        required_columns = {
            '–§–ò–û': ['—Ñ–∏–æ', '—Ñio', '–∏–º—è', 'name'],
            '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞': ['–∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', 'email', '–ø–æ—á—Ç–∞', 'e-mail'],
            '–§–∏–ª–∏–∞–ª (–∫–∞–º–ø—É—Å)': ['—Ñ–∏–ª–∏–∞–ª', '–∫–∞–º–ø—É—Å', 'campus'],
            '–§–∞–∫—É–ª—å—Ç–µ—Ç': ['—Ñ–∞–∫—É–ª—å—Ç–µ—Ç', 'faculty'],
            '–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞': ['–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ø—Ä–æ–≥—Ä–∞–º–º–∞', 'educational program'],
            '–ì—Ä—É–ø–ø–∞': ['–≥—Ä—É–ø–ø–∞', 'group'],
            '–ö—É—Ä—Å': ['–∫—É—Ä—Å', 'course']
        }
        
        # Find matching columns in the file
        found_columns = {}
        df_columns_lower = [str(col).lower().strip() for col in df.columns]
        
        for target_col, possible_names in required_columns.items():
            for col_idx, col_name in enumerate(df_columns_lower):
                if any(possible_name in col_name for possible_name in possible_names):
                    found_columns[target_col] = df.columns[col_idx]
                    break
        
        # Create new DataFrame with required columns
        result_df = pd.DataFrame()
        for target_col, source_col in found_columns.items():
            if source_col in df.columns:
                result_df[target_col] = df[source_col]
        
        # Check for '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ' column and parse it according to specification
        if '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ' in df.columns:
            user_data = df['–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ'].astype(str)
            parsed_data = user_data.str.split(';', expand=True)
            if len(parsed_data.columns) >= 4:
                result_df['–§–∞–∫—É–ª—å—Ç–µ—Ç'] = parsed_data[0]
                result_df['–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≥—Ä–∞–º–º–∞'] = parsed_data[1] 
                result_df['–ö—É—Ä—Å'] = parsed_data[2]
                result_df['–ì—Ä—É–ø–ø–∞'] = parsed_data[3]
        
        # Add missing columns with empty values
        for required_col in required_columns.keys():
            if required_col not in result_df.columns:
                result_df[required_col] = ''
        
        # Filter only students with edu.hse.ru email
        if '–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞' in result_df.columns:
            result_df = result_df[result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'].astype(str).str.contains('@edu.hse.ru', na=False)]
            result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'] = pd.Series(result_df['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞']).astype(str).str.lower().str.strip()
        
        return result_df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {str(e)}")
        return None

def extract_course_data(uploaded_file, course_name):
    """Extract email and completion percentage from uploaded course file (CSV or Excel)"""
    try:
        # Determine file type and load accordingly
        file_name = uploaded_file.name.lower()
        if file_name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        elif file_name.endswith('.csv'):
            # Read the uploaded file with different encoding options
            content = uploaded_file.getvalue()
            try:
                # Try UTF-16 with tab delimiter first (based on project memory)
                df = pd.read_csv(StringIO(content.decode('utf-16')), sep='\t')
            except (UnicodeDecodeError, pd.errors.ParserError):
                try:
                    # Try UTF-8 with comma delimiter
                    df = pd.read_csv(StringIO(content.decode('utf-8')))
                except UnicodeDecodeError:
                    # Try cp1251 encoding (common for Russian files)
                    df = pd.read_csv(StringIO(content.decode('cp1251')))
        else:
            st.error(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Excel (.xlsx, .xls) –∏–ª–∏ CSV (.csv)")
            return None
        
        # Look for email column with different possible names
        email_column = None
        possible_email_names = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', '–ê–¥—Ä–µ—Å —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–π –ø–æ—á—Ç—ã', 'Email', '–ü–æ—á—Ç–∞', 'E-mail']
        
        for col_name in possible_email_names:
            if col_name in df.columns:
                email_column = col_name
                break
        
        if email_column is None:
            st.error(f"–°—Ç–æ–ª–±–µ—Ü —Å email –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ {course_name}. –û–∂–∏–¥–∞—é—Ç—Å—è —Å—Ç–æ–ª–±—Ü—ã: {', '.join(possible_email_names)}")
            return None
        
        # Look for completion percentage column
        completion_column = None
        possible_completion_names = ['–ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è', 'Completion', 'Progress', '–ü—Ä–æ–≥—Ä–µ—Å—Å', '–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ']
        
        # Also check if we need to calculate completion from multiple columns
        # Look for columns that might contain completion data
        completed_columns = []
        timestamp_columns = []
        
        for col in df.columns:
            if col not in ['Unnamed: 0', email_column, '–î–∞–Ω–Ω—ã–µ –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ', 'User information', '–°—Ç—Ä–∞–Ω–∞']:
                # Check if this column contains completion data
                if not col.startswith('Unnamed:') and len(str(col).strip()) > 0:
                    # Sample some values to see if they contain "–í—ã–ø–æ–ª–Ω–µ–Ω–æ" –∏–ª–∏ "–ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ"
                    sample_values = df[col].dropna().astype(str).head(100)
                    if any('–í—ã–ø–æ–ª–Ω–µ–Ω–æ' in str(val) or '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ' in str(val).lower() for val in sample_values):
                        # Skip informational columns (based on experience memory)
                        if not all(str(val) == '–ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ' for val in sample_values if pd.notna(val)):
                            completed_columns.append(col)
                elif col.startswith('Unnamed:') and col != 'Unnamed: 0':
                    # Check if this unnamed column contains timestamps (completion indicators)
                    sample_values = df[col].dropna().astype(str).head(20)
                    for val in sample_values:
                        val_str = str(val).strip()
                        # Check if it looks like a timestamp
                        if any(pattern in val_str for pattern in ['2020', '2021', '2022', '2023', '2024']) and ':' in val_str:
                            timestamp_columns.append(col)
                            break
        
        # If we found timestamp columns, use them for completion calculation
        if timestamp_columns:
            st.info(f"–ù–∞–π–¥–µ–Ω–æ {len(timestamp_columns)} —Å—Ç–æ–ª–±—Ü–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            
            # Calculate completion percentage based on timestamps
            completion_data = []
            for idx, row in df.iterrows():
                email_val = row[email_column]
                if pd.isna(email_val) or '@edu.hse.ru' not in str(email_val).lower():
                    continue
                
                total_tasks = len(timestamp_columns)
                completed_tasks = 0
                
                for col in timestamp_columns:
                    cell_val = row[col]
                    val_str = str(cell_val).strip() if not pd.isna(cell_val) else ''
                    # Check if there's a valid timestamp (indicates completion)
                    if val_str and val_str != 'nan' and val_str != '':
                        # Verify it looks like a timestamp
                        if any(pattern in val_str for pattern in ['2020', '2021', '2022', '2023', '2024']) and ':' in val_str:
                            completed_tasks += 1
                
                # Calculate percentage
                percentage = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                completion_data.append({'email': str(email_val).lower().strip(), 'percentage': percentage})
            
            # Create result DataFrame
            if completion_data:
                result_df = pd.DataFrame(completion_data)
                result_df.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
                st.success(f"‚úÖ –†–∞—Å—Å—á–∏—Ç–∞–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è {len(result_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫—É—Ä—Å–∞ {course_name} –Ω–∞ –æ—Å–Ω–æ–≤–µ {len(timestamp_columns)} –∑–∞–¥–∞–Ω–∏–π")
                return result_df
            else:
                st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
                return None
        
        # If we found completion tracking columns, calculate percentage
        elif completed_columns:
            st.info(f"–ù–∞–π–¥–µ–Ω–æ {len(completed_columns)} —Å—Ç–æ–ª–±—Ü–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
            
            # Calculate completion percentage
            completion_data = []
            for idx, row in df.iterrows():
                email_val = row[email_column]
                if pd.isna(email_val) or '@edu.hse.ru' not in str(email_val).lower():
                    continue
                
                total_tasks = 0
                completed_tasks = 0
                
                for col in completed_columns:
                    cell_val = row[col]
                    val = str(cell_val).strip() if not pd.isna(cell_val) else ''
                    if val and val != 'nan':
                        total_tasks += 1
                        if '–í—ã–ø–æ–ª–Ω–µ–Ω–æ' in val or '–≤—ã–ø–æ–ª–Ω–µ–Ω–æ' in val.lower():
                            completed_tasks += 1
                
                # Calculate percentage
                percentage = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0
                completion_data.append({'email': str(email_val).lower().strip(), 'percentage': percentage})
            
            # Create result DataFrame
            if completion_data:
                result_df = pd.DataFrame(completion_data)
                result_df.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
                st.success(f"‚úÖ –†–∞—Å—Å—á–∏—Ç–∞–Ω –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –¥–ª—è {len(result_df)} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫—É—Ä—Å–∞ {course_name}")
                return result_df
            else:
                st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –¥–ª—è –∫—É—Ä—Å–∞ {course_name}")
                return None
        
        # Fallback: look for direct completion percentage column
        for col_name in possible_completion_names:
            if col_name in df.columns:
                completion_column = col_name
                break
        
        if completion_column is None:
            st.error(f"–°—Ç–æ–ª–±–µ—Ü —Å –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ {course_name}. –û–∂–∏–¥–∞—é—Ç—Å—è —Å—Ç–æ–ª–±—Ü—ã: {', '.join(possible_completion_names)}")
            st.info(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {', '.join([col for col in df.columns[:10]])}")
            return None
        
        # Extract the specific columns we need
        course_data = df[[email_column, completion_column]].copy()
        course_data.columns = ['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}']
        course_data['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'] = pd.Series(course_data['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞']).astype(str).str.lower().str.strip()
        
        # Filter only edu.hse.ru emails
        email_series = pd.Series(course_data['–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞'])
        course_data = course_data[email_series.str.contains('@edu.hse.ru', na=False)]
        
        return course_data
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∫—É—Ä—Å–∞ {course_name}: {str(e)}")
        return None

def consolidate_data(student_list, course_data_list, course_names):
    """Consolidate all course data with student list"""
    try:
        # Start with student list
        consolidated = student_list.copy()
        
        # Merge each course data
        for course_data, course_name in zip(course_data_list, course_names):
            if course_data is not None:
                consolidated = pd.merge(consolidated, course_data, on='–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞', how='left')
                # Fill NaN values with 0
                consolidated[f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'] = consolidated[f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'].fillna(0.0)
        
        return consolidated
    except Exception as e:
        st.error(f"Error consolidating data: {str(e)}")
        return None

def upload_to_google_sheets(client, data_df, batch_size=200):
    """Upload data to Google Sheets with progress bar"""
    try:
        # Open the Google Sheet
        spreadsheet = client.open('DC_stat')
        worksheet = spreadsheet.worksheet('–õ–∏—Å—Ç1')
        
        # Clear existing data
        st.info("–û—á–∏—Å—Ç–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –≤ Google Sheets...")
        worksheet.clear()
        
        # Upload headers first
        headers = data_df.columns.tolist()
        st.info("–ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤...")
        worksheet.update(values=[headers], range_name='A1')
        
        # Upload data in batches with progress bar
        total_rows = len(data_df)
        total_batches = ((total_rows-1) // batch_size) + 1
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        successful_batches = 0
        
        for i in range(0, total_rows, batch_size):
            batch_num = i // batch_size + 1
            batch_end = min(i + batch_size, total_rows)
            batch_data = data_df.iloc[i:batch_end]
            
            # Convert to list format
            data_batch = batch_data.replace({pd.NA: '', pd.NaT: '', None: ''}).values.tolist()
            
            # Calculate starting row for this batch
            start_row = i + 2
            start_cell = f"A{start_row}"
            
            try:
                status_text.text(f"–ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞–∫–µ—Ç–∞ {batch_num}/{total_batches}: —Å—Ç—Ä–æ–∫–∏ {i+1}-{batch_end}")
                worksheet.update(values=data_batch, range_name=start_cell)
                successful_batches += 1
                
                # Update progress bar
                progress = batch_num / total_batches
                progress_bar.progress(progress)
                
                # Small delay to avoid rate limiting
                time.sleep(0.5)
                
            except Exception as e:
                st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞–∫–µ—Ç {batch_num}: {str(e)}")
                return False
        
        progress_bar.progress(1.0)
        status_text.text(f"‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {successful_batches} –ø–∞–∫–µ—Ç–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
        return True
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ Google Sheets: {str(e)}")
        return False

def main():
    st.title("üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –∫—É—Ä—Å–æ–≤")
    st.markdown("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –∏ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –∞–Ω–∞–ª–∏—Ç–∏–∫—É –∫—É—Ä—Å–æ–≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
    
    # Sidebar for file uploads
    st.sidebar.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
    
    # File upload widgets
    student_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (Excel/CSV)",
        type=['xlsx', 'xls', 'csv'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel –∏–ª–∏ CSV —Ñ–∞–π–ª —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç—É–¥–µ–Ω—Ç–∞—Ö"
    )
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("–§–∞–π–ª—ã –∫—É—Ä—Å–æ–≤ (CSV/Excel)")
    
    course_cg_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –¶–ì",
        type=['csv', 'xlsx', 'xls'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª –¥–ª—è –∫—É—Ä—Å–∞ –¶–∏—Ñ—Ä–æ–≤–∞—è –≥—Ä–∞–º–æ—Ç–Ω–æ—Å—Ç—å"
    )
    
    course_python_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ Python",
        type=['csv', 'xlsx', 'xls'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª –¥–ª—è –∫—É—Ä—Å–∞ Python"
    )
    
    course_analysis_file = st.sidebar.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö",
        type=['csv', 'xlsx', 'xls'],
        help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ Excel —Ñ–∞–π–ª –¥–ª—è –∫—É—Ä—Å–∞ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"
    )
    
    # Main content area
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("üìã –°—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        # Check if all files are uploaded
        files_uploaded = all([
            student_file is not None,
            course_cg_file is not None,
            course_python_file is not None,
            course_analysis_file is not None
        ])
        
        if not files_uploaded:
            st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
            st.markdown("""
            - ‚úÖ –°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ (Excel –∏–ª–∏ CSV —Ñ–∞–π–ª)
            - ‚úÖ –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –¶–ì (CSV –∏–ª–∏ Excel —Ñ–∞–π–ª)  
            - ‚úÖ –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ Python (CSV –∏–ª–∏ Excel —Ñ–∞–π–ª)
            - ‚úÖ –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–∞ –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö (CSV –∏–ª–∏ Excel —Ñ–∞–π–ª)
            """)
            
            # Show upload status
            file_status = {
                "–°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤": "‚úÖ" if student_file else "‚ùå",
                "–ö—É—Ä—Å –¶–ì": "‚úÖ" if course_cg_file else "‚ùå",
                "–ö—É—Ä—Å Python": "‚úÖ" if course_python_file else "‚ùå",
                "–ö—É—Ä—Å –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö": "‚úÖ" if course_analysis_file else "‚ùå"
            }
            
            status_df = pd.DataFrame([{"–§–∞–π–ª": k, "–°—Ç–∞—Ç—É—Å": v} for k, v in file_status.items()])
            st.table(status_df)
        
        else:
            st.success("–í—Å–µ —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã! –ì–æ—Ç–æ–≤–æ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ.")
            
            if st.button("üöÄ –ù–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É", type="primary"):
                
                with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                    
                    # Step 1: Load student list
                    st.info("üìö –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤...")
                    student_list = load_student_list(student_file)
                    if student_list is None:
                        st.stop()
                    st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(student_list)} –∑–∞–ø–∏—Å–µ–π —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
                    
                    # Step 2: Process course files
                    st.info("üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –∫—É—Ä—Å–æ–≤...")
                    course_names = ['–¶–ì', '–ü–∏—Ç–æ–Ω', '–ê–Ω–¥–∞–Ω']
                    course_files = [course_cg_file, course_python_file, course_analysis_file]
                    course_data_list = []
                    
                    for course_file, course_name in zip(course_files, course_names):
                        course_data = extract_course_data(course_file, course_name)
                        if course_data is None:
                            st.stop()
                        course_data_list.append(course_data)
                        st.success(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω –∫—É—Ä—Å {course_name}: {len(course_data)} –∑–∞–ø–∏—Å–µ–π")
                    
                    # Step 3: Consolidate data
                    st.info("üîÑ –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
                    consolidated_data = consolidate_data(student_list, course_data_list, course_names)
                    if consolidated_data is None:
                        st.stop()
                    st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã: {len(consolidated_data)} –≤—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π")
                    
                    # Step 4: Show statistics
                    st.info("üìà –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏...")
                    stats_col1, stats_col2, stats_col3 = st.columns(3)
                    
                    for i, course_name in enumerate(course_names):
                        col_name = f'–ü—Ä–æ—Ü–µ–Ω—Ç_{course_name}'
                        if col_name in consolidated_data.columns:
                            avg_completion = consolidated_data[col_name].mean()
                            students_100 = len(consolidated_data[consolidated_data[col_name] == 100.0])
                            students_0 = len(consolidated_data[consolidated_data[col_name] == 0.0])
                            
                            with [stats_col1, stats_col2, stats_col3][i]:
                                st.metric(
                                    label=f"–ö—É—Ä—Å {course_name}",
                                    value=f"{avg_completion:.2f}%",
                                    delta=f"100%: {students_100} | 0%: {students_0}"
                                )
                    
                    # Step 5: Update Google Sheets
                    st.info("‚òÅÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Google Sheets...")
                    client = authenticate_google_sheets()
                    if client is None:
                        st.stop()
                    
                    success = upload_to_google_sheets(client, consolidated_data)
                    if success:
                        st.success("üéâ –í—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                        st.balloons()
                    else:
                        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ Google Sheets")
    
    with col2:
        st.header("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
        st.markdown("""
        **–°–∏—Å—Ç–µ–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
        - –°–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Excel (.xlsx, .xls) –∏–ª–∏ CSV (.csv)
        - –î–∞–Ω–Ω—ã–µ –∫—É—Ä—Å–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV (.csv) –∏–ª–∏ Excel (.xlsx, .xls) —Å–æ —Å—Ç–æ–ª–±—Ü–∞–º–∏:
          - `–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–æ—á—Ç–∞`
          - `–ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è`
        - –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ Google Sheets
        
        **–†–µ–∑—É–ª—å—Ç–∞—Ç:**
        - –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ Google Sheet "DC_stat"
        - –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—É–¥–µ–Ω—Ç–∞—Ö —Å –ø—Ä–æ—Ü–µ–Ω—Ç–∞–º–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        - –ù—É–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤, –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤ –¥–∞–Ω–Ω—ã—Ö –∫—É—Ä—Å–æ–≤
        
        **–≠—Ç–∞–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏:**
        1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–ø–∏—Å–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        2. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–µ—Ö —Ñ–∞–π–ª–æ–≤ –∫—É—Ä—Å–æ–≤
        3. –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ email
        4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        5. –ó–∞–≥—Ä—É–∑–∫–∞ –≤ Google Sheets
        
        **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏:**
        - UTF-8 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        - UTF-16 —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º —Ç–∞–±—É–ª—è—Ü–∏–∏
        - CP1251 (–¥–ª—è —Ä—É—Å—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤)
        """)
        
        if files_uploaded:
            st.markdown("---")
            st.success("–ì–æ—Ç–æ–≤–æ –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ!")

if __name__ == "__main__":
    main()
